use anyhow::Result;
use clap::{Parser, Subcommand};
use std::path::PathBuf;

use cleaner::Cleaner;
use detector::detect_dead_code;
use reporter::{generate_json_report, print_report};
use scanner::Scanner;

mod annotator;
mod cleaner;
mod detector;
mod graph;
mod llm;
mod parser;
mod reporter;
mod scanner;

#[derive(Parser)]
#[command(name = "index-chan")]
#[command(about = "TypeScript dead code detection CLI", long_about = None)]
struct Cli {
    #[command(subcommand)]
    command: Commands,
}

#[derive(Subcommand)]
enum Commands {
    /// Scan directory for dead code
    Scan {
        /// Target directory to scan
        #[arg(value_name = "DIRECTORY")]
        directory: PathBuf,

        /// Output report to JSON file
        #[arg(short, long, value_name = "FILE")]
        output: Option<PathBuf>,

        /// Use LLM for advanced analysis
        #[arg(long)]
        llm: bool,
    },

    /// Clean dead code (interactive or automatic)
    Clean {
        /// Target directory to clean
        #[arg(value_name = "DIRECTORY")]
        directory: PathBuf,

        /// Dry run (don't actually delete)
        #[arg(long)]
        dry_run: bool,

        /// Automatic mode (only delete definitely safe code)
        #[arg(long)]
        auto: bool,

        /// Only delete definitely safe code
        #[arg(long)]
        safe_only: bool,
    },

    /// Annotate code that should be kept (suppress warnings)
    Annotate {
        /// Target directory to annotate
        #[arg(value_name = "DIRECTORY")]
        directory: PathBuf,

        /// Use LLM for advanced analysis
        #[arg(long)]
        llm: bool,

        /// Dry run (don't actually modify files)
        #[arg(long)]
        dry_run: bool,
    },

    /// Test LLM inference with a simple prompt
    TestLlm {
        /// Custom prompt to test (optional)
        #[arg(short, long)]
        prompt: Option<String>,

        /// List available files in the model repository
        #[arg(long)]
        list_files: bool,

        /// Test tokenizer only (no inference)
        #[arg(long)]
        tokenizer_only: bool,
    },
}

fn main() -> Result<()> {
    let cli = Cli::parse();

    match cli.command {
        Commands::Scan {
            directory,
            output,
            llm,
        } => {
            println!("ğŸ” Scanning directory: {}", directory.display());
            if llm {
                println!("ğŸ¤– LLMåˆ†æãƒ¢ãƒ¼ãƒ‰æœ‰åŠ¹");
            }
            println!();

            let mut scanner = Scanner::new()?;
            let graph = scanner.scan_directory(&directory)?;

            let total_files = walkdir::WalkDir::new(&directory)
                .into_iter()
                .filter_map(|e| e.ok())
                .filter(|e| {
                    e.path().extension().and_then(|s| s.to_str()) == Some("ts")
                        || e.path().extension().and_then(|s| s.to_str()) == Some("tsx")
                })
                .count();

            let total_functions = graph.nodes.len();
            let mut dead_code = detect_dead_code(&graph);

            // LLM analysis if requested
            if llm {
                println!("ğŸ¤– LLMã§åˆ†æä¸­...");
                let llm_config = llm::LLMConfig::default();
                let mut llm_analyzer = llm::LLMAnalyzer::new(llm_config, true)?;
                let context_collector = llm::ContextCollector::new(&directory);

                for code in &mut dead_code {
                    let context = context_collector.collect_context(&code.node);
                    match llm_analyzer.analyze(&code.node, &context) {
                        Ok(analysis) => {
                            // Update reason with LLM analysis
                            code.reason = format!(
                                "{} (ç¢ºä¿¡åº¦: {:.0}%)",
                                analysis.reason,
                                analysis.confidence * 100.0
                            );

                            // Update safety level based on LLM analysis
                            if analysis.should_delete && analysis.confidence > 0.9 {
                                code.safety_level = detector::SafetyLevel::DefinitelySafe;
                            } else if !analysis.should_delete && analysis.confidence > 0.8 {
                                code.safety_level = detector::SafetyLevel::NeedsReview;
                            }
                        }
                        Err(e) => {
                            eprintln!("âš ï¸  LLMåˆ†æã‚¨ãƒ©ãƒ¼ ({}): {}", code.node.name, e);
                        }
                    }
                }
                println!("âœ… LLMåˆ†æå®Œäº†\n");
            }

            print_report(&dead_code, total_files, total_functions);

            if let Some(output_path) = output {
                let report = generate_json_report(&dead_code, total_files, total_functions);
                let json = serde_json::to_string_pretty(&report)?;
                std::fs::write(&output_path, json)?;
                println!("\nğŸ“„ Report saved to: {}", output_path.display());
            }

            Ok(())
        }
        Commands::Clean {
            directory,
            dry_run,
            auto,
            safe_only,
        } => {
            println!("ğŸ§¹ Cleaning directory: {}", directory.display());
            if dry_run {
                println!("(Dry run mode)");
            }
            println!();

            // ã‚¹ã‚­ãƒ£ãƒ³
            let mut scanner = Scanner::new()?;
            let graph = scanner.scan_directory(&directory)?;

            let dead_code = detect_dead_code(&graph);

            if dead_code.is_empty() {
                println!("âœ¨ ãƒ‡ãƒƒãƒ‰ã‚³ãƒ¼ãƒ‰ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ");
                return Ok(());
            }

            println!("\nå‰Šé™¤å€™è£œ: {}å€‹", dead_code.len());

            // ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ
            let cleaner = Cleaner::new(dry_run, auto, safe_only);
            let result = cleaner.clean(&dead_code)?;

            println!("\nğŸ“Š çµæœ:");
            println!(
                "  å‰Šé™¤: {}å€‹ ({}è¡Œ)",
                result.deleted_count, result.deleted_lines
            );
            println!("  ã‚¹ã‚­ãƒƒãƒ—: {}å€‹", result.skipped_count);

            if dry_run {
                println!("\nğŸ’¡ å®Ÿéš›ã«å‰Šé™¤ã™ã‚‹ã«ã¯ --dry-run ã‚’å¤–ã—ã¦ãã ã•ã„");
            }

            Ok(())
        }
        Commands::Annotate {
            directory,
            llm,
            dry_run,
        } => {
            println!("ğŸ“ ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³è¿½åŠ : {}", directory.display());
            if llm {
                println!("ğŸ¤– LLMåˆ†æãƒ¢ãƒ¼ãƒ‰æœ‰åŠ¹");
            }
            if dry_run {
                println!("(ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ãƒ¢ãƒ¼ãƒ‰)");
            }
            println!();

            // ã‚¹ã‚­ãƒ£ãƒ³
            let mut scanner = Scanner::new()?;
            let graph = scanner.scan_directory(&directory)?;

            let dead_code = detect_dead_code(&graph);

            if dead_code.is_empty() {
                println!("âœ¨ ãƒ‡ãƒƒãƒ‰ã‚³ãƒ¼ãƒ‰ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ");
                return Ok(());
            }

            println!("ğŸ“Š æ¤œå‡ºçµæœ: {}å€‹ã®æœªä½¿ç”¨é–¢æ•°", dead_code.len());

            // LLM analysis if requested
            let mut annotator = annotator::Annotator::new(dry_run);

            if llm {
                println!("ğŸ¤– LLMã§åˆ†æä¸­...");
                let llm_config = llm::LLMConfig::default();
                let mut llm_analyzer = llm::LLMAnalyzer::new(llm_config, true)?;
                let context_collector = llm::ContextCollector::new(&directory);

                let mut analyses = std::collections::HashMap::new();

                for code in &dead_code {
                    let context = context_collector.collect_context(&code.node);
                    match llm_analyzer.analyze(&code.node, &context) {
                        Ok(analysis) => {
                            let key =
                                format!("{}:{}", code.node.file_path.display(), code.node.name);
                            analyses.insert(
                                key,
                                annotator::LLMAnalysisData {
                                    should_delete: analysis.should_delete,
                                    confidence: analysis.confidence,
                                    reason: analysis.reason,
                                    category: format!("{:?}", analysis.category),
                                },
                            );
                        }
                        Err(e) => {
                            eprintln!("âš ï¸  LLMåˆ†æã‚¨ãƒ©ãƒ¼ ({}): {}", code.node.name, e);
                        }
                    }
                }

                annotator = annotator.with_llm_analyses(analyses);
                println!("âœ… LLMåˆ†æå®Œäº†\n");
            }

            // ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³è¿½åŠ 
            let result = annotator.annotate(&dead_code)?;

            println!("\nğŸ“ çµæœ:");
            println!("  ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³è¿½åŠ : {}å€‹", result.annotated_count);
            println!("  ã‚¹ã‚­ãƒƒãƒ—: {}å€‹", result.skipped_count);

            if dry_run {
                println!("\nğŸ’¡ å®Ÿéš›ã«è¿½åŠ ã™ã‚‹ã«ã¯ --dry-run ã‚’å¤–ã—ã¦ãã ã•ã„");
            } else {
                println!("\nâœ… ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ ã—ã¾ã—ãŸ");
            }

            Ok(())
        }
        Commands::TestLlm {
            prompt,
            list_files,
            tokenizer_only,
        } => {
            println!("ğŸ¤– LLMæ¨è«–ãƒ†ã‚¹ãƒˆé–‹å§‹\n");

            let config = llm::LLMConfig::default();

            if list_files {
                println!("ğŸ“‚ ãƒ¢ãƒ‡ãƒ«ãƒªãƒã‚¸ãƒˆãƒªã®ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’ç¢ºèªä¸­...");
                println!("  ãƒ¢ãƒ‡ãƒ«: {}\n", config.model_name);

                use hf_hub::api::sync::Api;
                let api = Api::new()?;
                let model_repo = api.model(config.model_name.clone());

                println!("ğŸ’¡ ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰è©¦è¡Œã—ã¾ã™:");
                let files = vec!["config.json", "tokenizer.json", "model.safetensors"];
                for file in files {
                    print!("  {} ... ", file);
                    match model_repo.get(file) {
                        Ok(path) => println!("âœ… å­˜åœ¨ ({})", path.display()),
                        Err(e) => println!("âŒ ã‚¨ãƒ©ãƒ¼: {}", e),
                    }
                }
                return Ok(());
            }

            let test_prompt = prompt.unwrap_or_else(|| {
                "ã“ã®é–¢æ•°ã¯å‰Šé™¤ã—ã¦ã‚‚å®‰å…¨ã§ã™ã‹ï¼Ÿ\n\nfunction unusedHelper() {\n  return 42;\n}"
                    .to_string()
            });

            println!("ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ:");
            println!("{}\n", test_prompt);

            println!("ğŸ”§ ãƒ¢ãƒ‡ãƒ«è¨­å®š:");
            println!("  ãƒ¢ãƒ‡ãƒ«å: {}", config.model_name);
            println!("  æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {}", config.max_tokens);
            println!("  æ¸©åº¦: {}", config.temperature);
            println!();

            if tokenizer_only {
                println!("ğŸ”§ ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®ã¿ãƒ†ã‚¹ãƒˆ\n");

                use tokenizers::Tokenizer;
                let tokenizer_path = std::path::PathBuf::from("models/tokenizer.json");

                if !tokenizer_path.exists() {
                    eprintln!(
                        "âŒ tokenizer.jsonãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {}",
                        tokenizer_path.display()
                    );
                    return Ok(());
                }

                println!("ğŸ“¥ ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...");
                let tokenizer = Tokenizer::from_file(tokenizer_path)
                    .map_err(|e| anyhow::anyhow!("ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—: {}", e))?;

                println!("âœ… ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®ãƒ­ãƒ¼ãƒ‰å®Œäº†\n");

                println!("ğŸ”¤ ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆ:");
                let encoding = tokenizer
                    .encode(test_prompt.as_str(), true)
                    .map_err(|e| anyhow::anyhow!("ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã«å¤±æ•—: {}", e))?;

                let tokens = encoding.get_ids();
                println!("  ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {}", tokens.len());
                println!("  ãƒˆãƒ¼ã‚¯ãƒ³ID: {:?}", &tokens[..tokens.len().min(10)]);

                println!("\nğŸ”¤ ãƒ‡ã‚³ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆ:");
                let decoded = tokenizer
                    .decode(tokens, true)
                    .map_err(|e| anyhow::anyhow!("ãƒ‡ã‚³ãƒ¼ãƒ‰ã«å¤±æ•—: {}", e))?;
                println!("  ãƒ‡ã‚³ãƒ¼ãƒ‰çµæœ: {}", decoded);

                println!("\nâœ… ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã¯æ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™");
                return Ok(());
            }

            println!("ğŸ“¥ ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...");
            println!("  (åˆå›å®Ÿè¡Œæ™‚ã¯æ•°åˆ†ã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™)");
            println!("  ğŸ’¡ ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª: cargo run -- test-llm --list-files");
            println!("  ğŸ’¡ ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®ã¿ãƒ†ã‚¹ãƒˆ: cargo run -- test-llm --tokenizer-only\n");

            match llm::LLMModel::new(config) {
                Ok(mut model) => {
                    println!("\nğŸš€ æ¨è«–å®Ÿè¡Œä¸­...");

                    match model.generate(&test_prompt) {
                        Ok(response) => {
                            println!("\nâœ… æ¨è«–æˆåŠŸï¼\n");
                            println!("ğŸ“¤ å¿œç­”:");
                            println!("{}", response);
                        }
                        Err(e) => {
                            eprintln!("\nâŒ æ¨è«–ã‚¨ãƒ©ãƒ¼: {}", e);
                            return Err(e);
                        }
                    }
                }
                Err(e) => {
                    eprintln!("\nâŒ ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {}", e);
                    eprintln!("\nğŸ’¡ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°:");
                    eprintln!("  1. ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„");
                    eprintln!("  2. HuggingFace Hubã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒå¯èƒ½ã‹ç¢ºèªã—ã¦ãã ã•ã„");
                    eprintln!("  3. ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼ˆç´„2GBå¿…è¦ï¼‰");
                    return Err(e);
                }
            }

            Ok(())
        }
    }
}
