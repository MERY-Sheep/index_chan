use anyhow::Result;
use clap::{Parser, Subcommand};
use std::path::PathBuf;

use cleaner::Cleaner;
use detector::detect_dead_code;
use reporter::{generate_json_report, print_report};
use scanner::Scanner;

mod annotator;
mod cleaner;
mod conversation;
mod detector;
mod exporter;
mod graph;
mod llm;
mod parser;
mod reporter;
mod scanner;
mod search;

#[cfg(feature = "web")]
mod web_server;

#[derive(Parser)]
#[command(name = "index-chan")]
#[command(about = "TypeScript dead code detection CLI", long_about = None)]
struct Cli {
    #[command(subcommand)]
    command: Commands,
}

#[derive(Subcommand)]
enum Commands {
    /// Scan directory for dead code
    Scan {
        /// Target directory to scan
        #[arg(value_name = "DIRECTORY")]
        directory: PathBuf,

        /// Output report to JSON file
        #[arg(short, long, value_name = "FILE")]
        output: Option<PathBuf>,

        /// Use LLM for advanced analysis
        #[arg(long)]
        llm: bool,
    },

    /// Clean dead code (interactive or automatic)
    Clean {
        /// Target directory to clean
        #[arg(value_name = "DIRECTORY")]
        directory: PathBuf,

        /// Dry run (don't actually delete)
        #[arg(long)]
        dry_run: bool,

        /// Automatic mode (only delete definitely safe code)
        #[arg(long)]
        auto: bool,

        /// Only delete definitely safe code
        #[arg(long)]
        safe_only: bool,
    },

    /// Annotate code that should be kept (suppress warnings)
    Annotate {
        /// Target directory to annotate
        #[arg(value_name = "DIRECTORY")]
        directory: PathBuf,

        /// Use LLM for advanced analysis
        #[arg(long)]
        llm: bool,

        /// Dry run (don't actually modify files)
        #[arg(long)]
        dry_run: bool,
    },

    /// Test LLM inference with a simple prompt
    TestLlm {
        /// Custom prompt to test (optional)
        #[arg(short, long)]
        prompt: Option<String>,

        /// List available files in the model repository
        #[arg(long)]
        list_files: bool,

        /// Test tokenizer only (no inference)
        #[arg(long)]
        tokenizer_only: bool,
    },

    /// Test embedding model
    TestEmbedding {
        /// Text to encode (optional)
        #[arg(short, long)]
        text: Option<String>,

        /// Compare similarity between two texts
        #[arg(long)]
        compare: bool,
    },

    /// Create search index for code
    Index {
        /// Target directory to index
        #[arg(value_name = "DIRECTORY")]
        directory: PathBuf,

        /// Output index file
        #[arg(short, long, value_name = "FILE", default_value = ".index-chan/index.json")]
        output: PathBuf,
    },

    /// Search for code
    Search {
        /// Search query
        #[arg(value_name = "QUERY")]
        query: String,

        /// Index file to search
        #[arg(short, long, value_name = "FILE", default_value = ".index-chan/index.json")]
        index: PathBuf,

        /// Number of results to return
        #[arg(short = 'k', long, default_value = "10")]
        top_k: usize,

        /// Include context in results
        #[arg(long)]
        context: bool,
    },

    /// Analyze chat history
    AnalyzeChat {
        /// Chat history JSON file
        #[arg(value_name = "FILE")]
        file: PathBuf,

        /// Output graph file
        #[arg(short, long, value_name = "FILE")]
        output: Option<PathBuf>,
    },

    /// Extract topics from chat history
    Topics {
        /// Chat history JSON file
        #[arg(value_name = "FILE")]
        file: PathBuf,

        /// Use LLM for advanced topic detection
        #[arg(long)]
        llm: bool,
    },

    /// Find related messages in chat history
    Related {
        /// Chat history JSON file
        #[arg(value_name = "FILE")]
        file: PathBuf,

        /// Query to find related messages
        #[arg(value_name = "QUERY")]
        query: String,

        /// Number of results to return
        #[arg(short = 'k', long, default_value = "5")]
        top_k: usize,

        /// Show context window around each result
        #[arg(long)]
        context: bool,
    },

    /// Export dependency graph for visualization
    Export {
        /// Target directory to analyze
        #[arg(value_name = "DIRECTORY")]
        directory: PathBuf,

        /// Output file path
        #[arg(short, long, value_name = "FILE")]
        output: PathBuf,

        /// Export format (graphml, dot, json)
        #[arg(short, long, default_value = "graphml")]
        format: String,
    },

    /// Visualize dependency graph in 3D (web server)
    #[cfg(feature = "web")]
    Visualize {
        /// Target directory to analyze
        #[arg(value_name = "DIRECTORY")]
        directory: PathBuf,

        /// Server port
        #[arg(short, long, default_value = "8080")]
        port: u16,

        /// Open browser automatically
        #[arg(long)]
        open: bool,
    },
}

fn main() -> Result<()> {
    let cli = Cli::parse();

    match cli.command {
        Commands::Scan {
            directory,
            output,
            llm,
        } => {
            println!("ğŸ” Scanning directory: {}", directory.display());
            if llm {
                println!("ğŸ¤– LLM analysis mode enabled");
            }
            println!();

            let mut scanner = Scanner::new()?;
            let graph = scanner.scan_directory(&directory)?;

            let total_files = walkdir::WalkDir::new(&directory)
                .into_iter()
                .filter_map(|e| e.ok())
                .filter(|e| {
                    e.path().extension().and_then(|s| s.to_str()) == Some("ts")
                        || e.path().extension().and_then(|s| s.to_str()) == Some("tsx")
                })
                .count();

            let total_functions = graph.nodes.len();
            let mut dead_code = detect_dead_code(&graph);

            // LLM analysis if requested
            if llm {
                println!("ğŸ¤– Analyzing with LLM...");
                let llm_config = llm::LLMConfig::default();
                let mut llm_analyzer = llm::LLMAnalyzer::new(llm_config, true)?;
                let context_collector = llm::ContextCollector::new(&directory);

                for code in &mut dead_code {
                    let context = context_collector.collect_context(&code.node);
                    match llm_analyzer.analyze(&code.node, &context) {
                        Ok(analysis) => {
                            // Update reason with LLM analysis
                            code.reason = format!(
                                "{} (confidence: {:.0}%)",
                                analysis.reason,
                                analysis.confidence * 100.0
                            );

                            // Update safety level based on LLM analysis
                            if analysis.should_delete && analysis.confidence > 0.9 {
                                code.safety_level = detector::SafetyLevel::DefinitelySafe;
                            } else if !analysis.should_delete && analysis.confidence > 0.8 {
                                code.safety_level = detector::SafetyLevel::NeedsReview;
                            }
                        }
                        Err(e) => {
                            eprintln!("âš ï¸  LLM analysis error ({}): {}", code.node.name, e);
                        }
                    }
                }
                println!("âœ… LLM analysis completed\n");
            }

            print_report(&dead_code, total_files, total_functions);

            if let Some(output_path) = output {
                let report = generate_json_report(&dead_code, total_files, total_functions);
                let json = serde_json::to_string_pretty(&report)?;
                std::fs::write(&output_path, json)?;
                println!("\nğŸ“„ Report saved to: {}", output_path.display());
            }

            Ok(())
        }
        Commands::Clean {
            directory,
            dry_run,
            auto,
            safe_only,
        } => {
            println!("ğŸ§¹ Cleaning directory: {}", directory.display());
            if dry_run {
                println!("(Dry run mode)");
            }
            println!();

            // ã‚¹ã‚­ãƒ£ãƒ³
            let mut scanner = Scanner::new()?;
            let graph = scanner.scan_directory(&directory)?;

            let dead_code = detect_dead_code(&graph);

            if dead_code.is_empty() {
                println!("âœ¨ No dead code found");
                return Ok(());
            }

            println!("\nDeletion candidates: {} items", dead_code.len());

            // Execute cleaning
            let cleaner = Cleaner::new(dry_run, auto, safe_only);
            let result = cleaner.clean(&dead_code)?;

            println!("\nğŸ“Š Results:");
            println!(
                "  Deleted: {} items ({} lines)",
                result.deleted_count, result.deleted_lines
            );
            println!("  Skipped: {} items", result.skipped_count);

            if dry_run {
                println!("\nğŸ’¡ Remove --dry-run flag to actually delete");
            }

            Ok(())
        }
        Commands::Annotate {
            directory,
            llm,
            dry_run,
        } => {
            println!("ğŸ“ Adding annotations: {}", directory.display());
            if llm {
                println!("ğŸ¤– LLM analysis mode enabled");
            }
            if dry_run {
                println!("(Dry run mode)");
            }
            println!();

            // ã‚¹ã‚­ãƒ£ãƒ³
            let mut scanner = Scanner::new()?;
            let graph = scanner.scan_directory(&directory)?;

            let dead_code = detect_dead_code(&graph);

            if dead_code.is_empty() {
                println!("âœ¨ No dead code found");
                return Ok(());
            }

            println!("ğŸ“Š Detection results: {} unused functions", dead_code.len());

            // LLM analysis if requested
            let mut annotator = annotator::Annotator::new(dry_run);

            if llm {
                println!("ğŸ¤– Analyzing with LLM...");
                let llm_config = llm::LLMConfig::default();
                let mut llm_analyzer = llm::LLMAnalyzer::new(llm_config, true)?;
                let context_collector = llm::ContextCollector::new(&directory);

                let mut analyses = std::collections::HashMap::new();

                for code in &dead_code {
                    let context = context_collector.collect_context(&code.node);
                    match llm_analyzer.analyze(&code.node, &context) {
                        Ok(analysis) => {
                            let key =
                                format!("{}:{}", code.node.file_path.display(), code.node.name);
                            analyses.insert(
                                key,
                                annotator::LLMAnalysisData {
                                    should_delete: analysis.should_delete,
                                    confidence: analysis.confidence,
                                    reason: analysis.reason,
                                    category: format!("{:?}", analysis.category),
                                },
                            );
                        }
                        Err(e) => {
                            eprintln!("âš ï¸  LLM analysis error ({}): {}", code.node.name, e);
                        }
                    }
                }

                annotator = annotator.with_llm_analyses(analyses);
                println!("âœ… LLM analysis completed\n");
            }

            // ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³è¿½åŠ 
            let result = annotator.annotate(&dead_code)?;

            println!("\nğŸ“ Results:");
            println!("  Annotations added: {} items", result.annotated_count);
            println!("  Skipped: {} items", result.skipped_count);

            if dry_run {
                println!("\nğŸ’¡ Remove --dry-run flag to actually add annotations");
            } else {
                println!("\nâœ… Annotations added successfully");
            }

            Ok(())
        }
        Commands::TestLlm {
            prompt,
            list_files,
            tokenizer_only,
        } => {
            println!("ğŸ¤– Starting LLM inference test\n");

            let config = llm::LLMConfig::default();

            if list_files {
                println!("ğŸ“‚ Checking model repository files...");
                println!("  Model: {}\n", config.model_name);

                use hf_hub::api::sync::Api;
                let api = Api::new()?;
                let model_repo = api.model(config.model_name.clone());

                println!("ğŸ’¡ Attempting to download the following files:");
                let files = vec!["config.json", "tokenizer.json", "model.safetensors"];
                for file in files {
                    print!("  {} ... ", file);
                    match model_repo.get(file) {
                        Ok(path) => println!("âœ… Exists ({})", path.display()),
                        Err(e) => println!("âŒ Error: {}", e),
                    }
                }
                return Ok(());
            }

            let test_prompt = prompt.unwrap_or_else(|| {
                "Is this function safe to delete?\n\nfunction unusedHelper() {\n  return 42;\n}"
                    .to_string()
            });

            println!("ğŸ“ Prompt:");
            println!("{}\n", test_prompt);

            println!("ğŸ”§ Model configuration:");
            println!("  Model name: {}", config.model_name);
            println!("  Max tokens: {}", config.max_tokens);
            println!("  Temperature: {}", config.temperature);
            println!();

            if tokenizer_only {
                println!("ğŸ”§ Testing tokenizer only\n");

                use tokenizers::Tokenizer;
                let tokenizer_path = std::path::PathBuf::from("models/tokenizer.json");

                if !tokenizer_path.exists() {
                    eprintln!(
                        "âŒ tokenizer.json not found: {}",
                        tokenizer_path.display()
                    );
                    return Ok(());
                }

                println!("ğŸ“¥ Loading tokenizer...");
                let tokenizer = Tokenizer::from_file(tokenizer_path)
                    .map_err(|e| anyhow::anyhow!("Failed to load tokenizer: {}", e))?;

                println!("âœ… Tokenizer loaded successfully\n");

                println!("ğŸ”¤ Encoding test:");
                let encoding = tokenizer
                    .encode(test_prompt.as_str(), true)
                    .map_err(|e| anyhow::anyhow!("Failed to encode: {}", e))?;

                let tokens = encoding.get_ids();
                println!("  Token count: {}", tokens.len());
                println!("  Token IDs: {:?}", &tokens[..tokens.len().min(10)]);

                println!("\nğŸ”¤ Decoding test:");
                let decoded = tokenizer
                    .decode(tokens, true)
                    .map_err(|e| anyhow::anyhow!("Failed to decode: {}", e))?;
                println!("  Decoded result: {}", decoded);

                println!("\nâœ… Tokenizer is working correctly");
                return Ok(());
            }

            println!("ğŸ“¥ Loading model...");
            println!("  (First run may take several minutes)");
            println!("  ğŸ’¡ Check files: cargo run -- test-llm --list-files");
            println!("  ğŸ’¡ Test tokenizer only: cargo run -- test-llm --tokenizer-only\n");

            match llm::LLMModel::new(config) {
                Ok(mut model) => {
                    println!("\nğŸš€ Running inference...");

                    match model.generate(&test_prompt) {
                        Ok(response) => {
                            println!("\nâœ… Inference successful!\n");
                            println!("ğŸ“¤ Response:");
                            println!("{}", response);
                        }
                        Err(e) => {
                            eprintln!("\nâŒ Inference error: {}", e);
                            return Err(e);
                        }
                    }
                }
                Err(e) => {
                    eprintln!("\nâŒ Model loading error: {}", e);
                    eprintln!("\nğŸ’¡ Troubleshooting:");
                    eprintln!("  1. Check your internet connection");
                    eprintln!("  2. Verify access to HuggingFace Hub");
                    eprintln!("  3. Check disk space (approximately 2GB required)");
                    return Err(e);
                }
            }

            Ok(())
        }
        Commands::Index { directory, output } => {
            println!("ğŸ“š Creating index: {}", directory.display());
            println!();

            // Scan directory
            let mut scanner = Scanner::new()?;
            let graph = scanner.scan_directory(&directory)?;

            println!("ğŸ“Š Found {} functions", graph.nodes.len());

            // Create index
            let mut index = search::CodeIndex::new()?;

            for (_id, node) in &graph.nodes {
                // Get dependencies
                let dependencies: Vec<String> = graph
                    .edges
                    .iter()
                    .filter(|e| e.from == node.id)
                    .filter_map(|e| graph.nodes.get(&e.to).map(|n| n.name.clone()))
                    .collect();

                let metadata = search::index::CodeMetadata {
                    file_path: node.file_path.clone(),
                    function_name: node.name.clone(),
                    start_line: node.line_range.0,
                    end_line: node.line_range.1,
                    code_snippet: format!("{:?}", node.node_type), // TODO: Get actual code snippet
                    dependencies,
                };
                index.add(metadata)?;
            }

            println!("âœ… Indexed {} items", index.len());

            // Save index
            if let Some(parent) = output.parent() {
                std::fs::create_dir_all(parent)?;
            }
            index.save(&output)?;

            println!("ğŸ’¾ Index saved to: {}", output.display());

            Ok(())
        }
        Commands::Search {
            query,
            index: index_path,
            top_k,
            context,
        } => {
            println!("ğŸ” Searching: {}", query);
            println!();

            // Load index
            let mut index = search::CodeIndex::new()?;
            
            if !index_path.exists() {
                eprintln!("âŒ Index file not found: {}", index_path.display());
                eprintln!("ğŸ’¡ Create index first: index-chan index <directory>");
                return Ok(());
            }

            index.load(&index_path)?;
            println!("ğŸ“š Loaded index: {} items", index.len());
            println!();

            // Search
            let results = index.search(&query, top_k)?;

            if results.is_empty() {
                println!("No results found");
                return Ok(());
            }

            println!("ğŸ“Š Found {} results:\n", results.len());

            for (i, result) in results.iter().enumerate() {
                println!("{}. {} (score: {:.2})", i + 1, result.metadata.function_name, result.score);
                println!("   ğŸ“„ {}:{}:{}", 
                    result.metadata.file_path.display(),
                    result.metadata.start_line,
                    result.metadata.end_line
                );
                
                if context {
                    println!("   ğŸ“ Code:");
                    for line in result.metadata.code_snippet.lines().take(5) {
                        println!("      {}", line);
                    }
                    if result.metadata.code_snippet.lines().count() > 5 {
                        println!("      ...");
                    }
                }
                
                if !result.metadata.dependencies.is_empty() {
                    println!("   ğŸ”— Dependencies: {}", result.metadata.dependencies.join(", "));
                }
                
                println!();
            }

            Ok(())
        }
        Commands::AnalyzeChat { file, output } => {
            println!("ğŸ’¬ Analyzing chat history: {}", file.display());
            println!();

            if !file.exists() {
                eprintln!("âŒ File not found: {}", file.display());
                return Ok(());
            }

            // Analyze chat
            let analyzer = conversation::ConversationAnalyzer::new()?;
            let mut graph = analyzer.analyze_file(&file)?;

            println!("ğŸ“Š Chat statistics:");
            let stats = graph.stats();
            println!("  Messages: {}", stats.total_messages);
            println!("  Edges: {}", stats.total_edges);
            println!("  Avg edges per message: {:.2}", stats.avg_edges_per_node);
            println!();

            // Detect topics
            let mut topic_detector = conversation::TopicDetector::new();
            topic_detector.detect_topics(&mut graph)?;

            println!("ğŸ“š Topics detected: {}", graph.topics.len());
            for topic in &graph.topics {
                println!("  - {} ({} messages)", topic.name, topic.message_ids.len());
            }
            println!();

            // Calculate token reduction
            let reduction = analyzer.calculate_token_reduction(&graph, None);
            println!("ğŸ¯ Token reduction:");
            println!("  Total tokens: {}", reduction.total_tokens);
            println!("  Relevant tokens: {}", reduction.relevant_tokens);
            println!("  Reduction rate: {:.1}%", reduction.reduction_rate * 100.0);

            // Save graph
            if let Some(output_path) = output {
                let json = serde_json::to_string_pretty(&graph)?;
                std::fs::write(&output_path, json)?;
                println!("\nğŸ’¾ Graph saved to: {}", output_path.display());
            }

            Ok(())
        }
        Commands::Topics { file, llm } => {
            println!("ğŸ“š ãƒˆãƒ”ãƒƒã‚¯æŠ½å‡º: {}", file.display());
            if llm {
                println!("ğŸ¤– LLMåˆ†æãƒ¢ãƒ¼ãƒ‰æœ‰åŠ¹");
            }
            println!();

            if !file.exists() {
                eprintln!("âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {}", file.display());
                return Ok(());
            }

            // Analyze chat
            let analyzer = conversation::ConversationAnalyzer::new()?;
            let mut graph = analyzer.analyze_file(&file)?;

            // Detect topics
            let mut topic_detector = if llm {
                println!("ğŸ¤– LLMã§ãƒˆãƒ”ãƒƒã‚¯ã‚’åˆ†æä¸­...");
                let llm_config = llm::LLMConfig::default();
                conversation::TopicDetector::with_llm(llm_config)?
            } else {
                conversation::TopicDetector::new()
            };
            
            topic_detector.detect_topics(&mut graph)?;

            if graph.topics.is_empty() {
                println!("ãƒˆãƒ”ãƒƒã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ");
                return Ok(());
            }

            println!("ğŸ“Š {}å€‹ã®ãƒˆãƒ”ãƒƒã‚¯ã‚’æ¤œå‡º:\n", graph.topics.len());

            for (i, topic) in graph.topics.iter().enumerate() {
                println!("{}. {}", i + 1, topic.name);
                println!("   ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°: {}", topic.message_ids.len());
                println!("   ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {}", topic.keywords.join(", "));
                println!();
            }

            Ok(())
        }
        Commands::TestEmbedding { text, compare } => {
            println!("ğŸ§ª Embeddingãƒ¢ãƒ‡ãƒ«ã®ãƒ†ã‚¹ãƒˆ\n");

            let config = search::embeddings::EmbeddingConfig::default();
            println!("ğŸ“ è¨­å®š:");
            println!("  ãƒ¢ãƒ‡ãƒ«: {}", config.model_name);
            println!("  æ¬¡å…ƒæ•°: {}", config.dimension);
            println!("  æœ€å¤§é•·: {}\n", config.max_length);

            println!("ğŸ“¥ ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...");
            let model = search::embeddings::EmbeddingModel::new(config)?;
            println!();

            if compare {
                let text1 = "function authenticate(user, password) { return true; }";
                let text2 = "function login(username, pwd) { return checkCredentials(username, pwd); }";
                let text3 = "function calculateTotal(items) { return items.reduce((sum, item) => sum + item.price, 0); }";

                println!("ğŸ“Š é¡ä¼¼åº¦æ¯”è¼ƒãƒ†ã‚¹ãƒˆ:\n");
                println!("ãƒ†ã‚­ã‚¹ãƒˆ1: {}", text1);
                println!("ãƒ†ã‚­ã‚¹ãƒˆ2: {}", text2);
                println!("ãƒ†ã‚­ã‚¹ãƒˆ3: {}\n", text3);

                println!("ğŸ”„ ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ä¸­...");
                let vec1 = model.encode(text1)?;
                let vec2 = model.encode(text2)?;
                let vec3 = model.encode(text3)?;

                let sim_1_2 = search::embeddings::EmbeddingModel::cosine_similarity(&vec1, &vec2);
                let sim_1_3 = search::embeddings::EmbeddingModel::cosine_similarity(&vec1, &vec3);
                let sim_2_3 = search::embeddings::EmbeddingModel::cosine_similarity(&vec2, &vec3);

                println!("\nğŸ“ˆ é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢:");
                println!("  ãƒ†ã‚­ã‚¹ãƒˆ1 vs ãƒ†ã‚­ã‚¹ãƒˆ2 (èªè¨¼é–¢é€£): {:.4}", sim_1_2);
                println!("  ãƒ†ã‚­ã‚¹ãƒˆ1 vs ãƒ†ã‚­ã‚¹ãƒˆ3 (ç•°ãªã‚‹æ©Ÿèƒ½): {:.4}", sim_1_3);
                println!("  ãƒ†ã‚­ã‚¹ãƒˆ2 vs ãƒ†ã‚­ã‚¹ãƒˆ3 (ç•°ãªã‚‹æ©Ÿèƒ½): {:.4}", sim_2_3);

                println!("\nğŸ’¡ æœŸå¾…ã•ã‚Œã‚‹çµæœ:");
                println!("  - èªè¨¼é–¢é€£ã®é–¢æ•°åŒå£«ï¼ˆ1 vs 2ï¼‰ã®é¡ä¼¼åº¦ãŒé«˜ã„");
                println!("  - ç•°ãªã‚‹æ©Ÿèƒ½ã®é–¢æ•°ï¼ˆ1 vs 3, 2 vs 3ï¼‰ã®é¡ä¼¼åº¦ãŒä½ã„");
            } else {
                let test_text = text.unwrap_or_else(|| {
                    "function getUserById(id) { return database.query('SELECT * FROM users WHERE id = ?', [id]); }".to_string()
                });

                println!("ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆ:");
                println!("{}\n", test_text);

                println!("ğŸ”„ ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ä¸­...");
                let vector = model.encode(&test_text)?;

                println!("\nâœ… ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰æˆåŠŸ!");
                println!("  ãƒ™ã‚¯ãƒˆãƒ«æ¬¡å…ƒ: {}", vector.len());
                println!("  æœ€åˆã®10è¦ç´ : {:?}", &vector[..10.min(vector.len())]);

                // Calculate L2 norm
                let norm: f32 = vector.iter().map(|x| x * x).sum::<f32>().sqrt();
                println!("  L2ãƒãƒ«ãƒ : {:.6}", norm);
                println!("\nğŸ’¡ L2ãƒãƒ«ãƒ ãŒ1.0ã«è¿‘ã„å ´åˆã€æ­£è¦åŒ–ã•ã‚Œã¦ã„ã¾ã™");
            }

            Ok(())
        }
        Commands::Related { file, query, top_k, context } => {
            println!("ğŸ” é–¢é€£ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ¤œç´¢: {}", file.display());
            println!("ğŸ“ ã‚¯ã‚¨ãƒª: {}\n", query);

            if !file.exists() {
                eprintln!("âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {}", file.display());
                return Ok(());
            }

            // Analyze chat
            let analyzer = conversation::ConversationAnalyzer::new()?;
            let graph = analyzer.analyze_file(&file)?;

            println!("ğŸ“Š ä¼šè©±çµ±è¨ˆ:");
            let stats = graph.stats();
            println!("  ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°: {}", stats.total_messages);
            println!();

            // Find related messages
            println!("ğŸ” é–¢é€£ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ¤œç´¢ä¸­...");
            let related = analyzer.find_related_messages(&graph, &query, top_k)?;

            if related.is_empty() {
                println!("é–¢é€£ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ");
                return Ok(());
            }

            println!("ğŸ“Š {}ä»¶ã®é–¢é€£ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç™ºè¦‹:\n", related.len());

            for (i, msg) in related.iter().enumerate() {
                println!("{}. [{}] {} (é¡ä¼¼åº¦: {:.3})", 
                    i + 1, 
                    msg.role, 
                    msg.timestamp,
                    msg.similarity
                );
                
                if let Some(topic_id) = &msg.topic_id {
                    if let Some(topic) = graph.topics.iter().find(|t| &t.id == topic_id) {
                        println!("   ğŸ·ï¸  ãƒˆãƒ”ãƒƒã‚¯: {}", topic.name);
                    }
                }
                
                println!("   ğŸ’¬ {}", msg.content);
                
                if context {
                    let context_msgs = graph.get_context_window(&msg.id, 1);
                    if context_msgs.len() > 1 {
                        println!("   ğŸ“– ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ:");
                        for ctx_msg in context_msgs {
                            if ctx_msg.id != msg.id {
                                println!("      [{}] {}", ctx_msg.role, 
                                    ctx_msg.content.chars().take(60).collect::<String>());
                            }
                        }
                    }
                }
                
                println!();
            }

            // Calculate token reduction
            let reduction = analyzer.calculate_token_reduction(&graph, Some(&query));
            println!("ğŸ¯ ãƒˆãƒ¼ã‚¯ãƒ³å‰Šæ¸›åŠ¹æœ:");
            println!("  å…¨ä½“ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {}", reduction.total_tokens);
            println!("  é–¢é€£ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {}", reduction.relevant_tokens);
            println!("  å‰Šæ¸›ç‡: {:.1}%", reduction.reduction_rate * 100.0);

            Ok(())
        }
        Commands::Export { directory, output, format } => {
            println!("ğŸ“Š ã‚°ãƒ©ãƒ•ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆä¸­: {}", directory.display());
            println!("ğŸ“ å‡ºåŠ›å…ˆ: {}", output.display());
            println!("ğŸ“‹ å½¢å¼: {}\n", format);

            if !directory.exists() {
                eprintln!("âŒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {}", directory.display());
                return Ok(());
            }

            // Scan directory
            let mut scanner = Scanner::new()?;
            let graph = scanner.scan_directory(&directory)?;

            println!("ğŸ“Š ã‚°ãƒ©ãƒ•çµ±è¨ˆ:");
            println!("  ãƒãƒ¼ãƒ‰æ•°: {}", graph.nodes.len());
            println!("  ã‚¨ãƒƒã‚¸æ•°: {}", graph.edges.len());
            println!();

            // Export based on format
            match format.to_lowercase().as_str() {
                "graphml" => {
                    exporter::GraphExporter::export_graphml(&graph, &output)?;
                    println!("âœ… GraphMLå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº†");
                    println!("ğŸ’¡ Gephiã€yEdã€Cytoscapeã§é–‹ã‘ã¾ã™");
                }
                "dot" => {
                    exporter::GraphExporter::export_dot(&graph, &output)?;
                    println!("âœ… DOTå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº†");
                    println!("ğŸ’¡ Graphvizã§å¯è¦–åŒ–:");
                    println!("   dot -Tsvg {} -o graph.svg", output.display());
                    println!("   neato -Tpng {} -o graph.png", output.display());
                }
                "json" => {
                    exporter::GraphExporter::export_json(&graph, &output)?;
                    println!("âœ… JSONå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº†");
                    println!("ğŸ’¡ ã‚«ã‚¹ã‚¿ãƒ å¯è¦–åŒ–ãƒ„ãƒ¼ãƒ«ã§ä½¿ç”¨ã§ãã¾ã™");
                }
                _ => {
                    eprintln!("âŒ æœªå¯¾å¿œã®å½¢å¼: {}", format);
                    eprintln!("ğŸ’¡ å¯¾å¿œå½¢å¼: graphml, dot, json");
                    return Ok(());
                }
            }

            println!("\nğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {} bytes", std::fs::metadata(&output)?.len());

            Ok(())
        }
        #[cfg(feature = "web")]
        Commands::Visualize {
            directory,
            port,
            open,
        } => {
            println!("ğŸ“Š ä¾å­˜é–¢ä¿‚ã‚°ãƒ©ãƒ•ã‚’å¯è¦–åŒ–ä¸­: {}", directory.display());
            println!();

            if !directory.exists() {
                eprintln!("âŒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {}", directory.display());
                return Ok(());
            }

            // Scan directory
            let mut scanner = Scanner::new()?;
            let graph = scanner.scan_directory(&directory)?;

            println!("ğŸ“Š ã‚°ãƒ©ãƒ•çµ±è¨ˆ:");
            println!("  ãƒãƒ¼ãƒ‰æ•°: {}", graph.nodes.len());
            println!("  ã‚¨ãƒƒã‚¸æ•°: {}", graph.edges.len());
            println!();

            // Open browser if requested
            if open {
                let url = format!("http://localhost:{}", port);
                println!("ğŸŒ ãƒ–ãƒ©ã‚¦ã‚¶ã‚’é–‹ã„ã¦ã„ã¾ã™: {}", url);
                #[cfg(feature = "web")]
                {
                    use std::process::Command;
                    let _ = Command::new("cmd")
                        .args(&["/C", "start", &url])
                        .spawn();
                }
            }

            // Start web server (requires tokio runtime)
            #[cfg(feature = "web")]
            {
                let runtime = tokio::runtime::Runtime::new()?;
                runtime.block_on(async {
                    web_server::server::start_server(graph, port).await
                })?;
            }

            Ok(())
        }
    }
}
