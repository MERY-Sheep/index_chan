# Index Librorum Prohibitorum（禁書目録）企画書
## コード依存グラフ型 LLM 向け検索システム

## 1. 概要

本企画は、ベクトル検索と依存グラフ探索を組み合わせた新しいコード検索システム「**Index Librorum Prohibitorum（禁書目録）**」を構築するものである。

従来のテキスト検索やベクトル検索単体では、関係のないコード片が混入し、LLM の回答品質を下げる「コンテキスト汚染」が課題となっていた。本システムは、ベクトル検索で起点を特定し、依存グラフで論理的に関連するコードを芋づる式に抽出することで、必要最小限かつ整合性の高いコンテキストを LLM に提供する。

### システムの動作フロー

```
自然言語クエリ
  ↓
ベクトル検索（トップk件の関数/ファイルを取得）
  ↓
起点候補 [func_a, func_b, func_c]
  ↓
各起点から依存グラフ探索（呼び出し先・呼び出し元・型定義）
  ↓
結果をマージ・優先度付け
  ↓
LLM へ最適化されたコンテキストを提供
```

## 2. 背景と課題

### 2.1 LLM がコード検索で直面する課題

- ファイル間の依存関係が複雑化し、必要な情報が分散する
- ベクトル検索では、語彙的に近くても論理的に関係のないコードが混ざる
- 依存の方向性（呼び出し関係、型関係）が検索結果に反映されない
- 結果として、LLM が誤ったコンテキストを基に推論し、誤回答につながる

### 2.2 既存ツールとの比較

**ベクトル検索のみ（GitHub Copilot など）**
- 長所: 自然言語から柔軟に検索できる
- 短所: 論理的な依存関係を無視、無関係なコードが混入

**グラフ探索のみ（LSP の定義ジャンプなど）**
- 長所: 正確な依存関係を辿れる
- 短所: 起点を手動で指定する必要がある、自然言語クエリに対応できない

**本システムの差別化**
- ベクトル検索で「だいたいこの辺」を自動特定
- グラフ探索で「論理的に必要なもの」を漏れなく収集
- 両者の強みを組み合わせた新しいアプローチ

## 3. システムのコンセプト

### 3.1 ハイブリッド検索アーキテクチャ

**ステップ1: ベクトル検索による起点特定**
- 関数・クラス単位で埋め込みベクトルを生成（docstring/コメント含む）
- 自然言語クエリに対してトップk件（k=3〜5）を取得
- 複数の起点候補を確保することで、検索失敗のリスクを低減

**ステップ2: 依存グラフ探索**
- 各起点から以下を探索:
  - 呼び出し先（2ホップ）
  - 呼び出し元（1ホップ）
  - 型定義・インターフェース
  - 同一ファイル内の関連関数
- 探索結果に優先度を付与（直接依存 > 間接依存）

**ステップ3: コンテキスト最適化**
- 重複排除（複数起点から同じコードに到達した場合）
- トークン制限に応じて優先度の低いものを削除
- 起点ごとにグループ化して LLM に提示

### 3.2 依存グラフの構造

**ノード**
- 関数
- クラス/型
- モジュール/ファイル

**エッジ**
- 呼び出し関係（call）
- 参照関係（reference）
- 継承関係（extends/implements）
- import/export 関係

**解析基盤**
- tree-sitter による多言語パーシング
- AST 解析による依存関係抽出

### 3.3 統合コンテキストによる一括編集

**従来の問題点**
- ファイルを個別に読み込み・編集するため遅い
- ファイル間の整合性を保つのが難しい
- 変更漏れが発生しやすい

**本システムのアプローチ**
```
依存グラフで関連ファイルを一括取得
  ↓
全ファイルを統合コンテキスト化
  ↓
LLM が全体を見ながら変更計画を生成
  ↓
差分を一括マージ・適用
```

**利点**
- 整合性: LLM が全体を見るので変更漏れがない
- 高速: ファイル読み書きと LLM リクエストが最小限
- 原子性: 全部成功するか全部失敗するか（中途半端な状態を回避）
- レビュー性: 変更全体を一度に確認可能

### 3.4 Index-chan（インデックスちゃん）: 依存グラフ管理特化型 LLM

**コンセプト**

常駐型の小型特化 LLM（1B〜3B パラメータ）「**Index-chan（インデックスちゃん）**」が依存グラフを監視・整理・最適化する。コードベースの司書として、大型 LLM がコード編集する際の「アシスタント」として機能し、グラフの健全性を保つ。

**主要機能**

1. リアルタイム整合性チェック
   - コード変更を検知し、依存関係の破綻を即座に警告
   - 循環参照、未使用 import、孤立ノードの検出

2. デッドコード自動検出
   - 完全に使われていない関数・クラス
   - 意味のないゾンビコード（何もしない関数）
   - 古いバージョンの残骸
   - テストされていないコード

3. 自動クリーンアップ提案
   - 削除可能なコードを優先度付きでリスト化
   - 安全性評価（リスクなし/低/中/高）
   - ワンクリックでの一括削除

4. グラフ最適化提案
   - 密結合の検出と統合提案
   - 疎結合化のための設計改善案
   - 3D グラフ可視化の配置最適化

**技術的特徴**

- 軽量: 量子化で 1GB 以下、CPU でも実行可能
- 常駐: バックグラウンドで継続的に監視
- 高速: グラフ操作に特化した推論で即座に反応
- 学習: オープンソースプロジェクトから大量の学習データ生成可能

**実用例**

```bash
$ code-graph health-check

📊 コード健全性レポート
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

🗑️  デッドコード: 23個 (456行)
├─ src/old-auth.ts:45-78 (oldAuthMethod)
├─ src/utils.ts:123-145 (deprecatedHelper)
└─ src/legacy.ts:1-234 (ファイル全体)

🧟 ゾンビコード: 8個 (92行)
├─ src/logger.ts:34-38 (emptyLogger)
└─ src/wrapper.ts:12-15 (simpleWrapper)

📦 未使用 import: 15個

💾 削減可能な行数: 548行 (全体の 12%)

🎯 推奨アクション:
1. [安全] src/legacy.ts を削除 (234行削減)
2. [安全] 未使用 import を削除 (15箇所)
3. [要確認] ゾンビコードを確認 (8箇所)
```

### 3.5 Rust による高性能実装

- Rust の速度と安全性を活かし、大規模プロジェクトでもスケール可能
- グラフ処理、インデックス構築、並列解析を効率的に実行
- インクリメンタル更新による高速な再解析

## 4. ターゲットユーザー

- 複雑なコードベースを日常的に扱うエンジニア
- LLM を利用したコードレビュー・改修・リファクタリングを行うチーム
- 大規模モノレポをもつ企業
- 静的解析やコード検索を高度化したい技術部門

## 5. システムの価値

### 5.1 技術的価値

- 依存関係に基づく正確なコンテキスト提供
- LLM の誤回答率・幻覚率の低下
- コンテキストサイズの最適化（不要なコードを排除）
- 多言語対応による広い適用範囲
- Graph Keeper による継続的なコード品質維持
- デッドコードの自動検出と削除による技術的負債の削減

### 5.2 ビジネス価値

- エンジニアの調査・検索時間を大幅に削減
- コードの理解・保守コストを低減
- 大規模開発チームの知識共有効率を向上
- オンボーディング時間の短縮
- 自動クリーンアップによるコードベースの肥大化防止
- 技術的負債の可視化と定量評価

### 5.3 競合優位性

- ベクトル検索とグラフ探索の組み合わせは既存ツールにない独自性
- 構造的理解に基づく「次世代のコード検索」を実現
- 統合コンテキストによる一括編集で、整合性の高いリファクタリングを実現
- LLM 時代に最適化された新しいツールカテゴリを創出

## 6. 成功指標（KPI）

### 定量指標

- LLM の回答精度: 正解率 80% 以上（ベースライン比 +20%）
- コンテキストサイズ削減率: 平均 40% 削減
- 検索時間: 1秒以内（1000ファイル規模のプロジェクト）
- 幻覚率: 30% 削減
- デッドコード検出率: 95% 以上
- コードベースサイズ削減: 平均 10〜15%

### 定性指標

- ユーザー満足度: NPS スコア 50 以上
- 開発者の検索効率: 「必要なコードが見つかる」と回答した割合 85% 以上

## 7. 開発フェーズ

### Phase 1: MVP（3ヶ月）

**目標**: 基本機能の実装と検証

- 単一言語対応（TypeScript または Python）
- ベクトル検索（既存ライブラリ使用）
- 基本的な依存グラフ構築（関数呼び出しのみ）
- デッドコード検出機能（ルールベース）
- 小規模プロジェクト（1000ファイル以下）での検証

**成果物**:
- プロトタイプ
- 精度評価レポート
- デッドコード検出精度レポート

### Phase 2: 精度向上（3ヶ月）

**目標**: 実用レベルへの引き上げ

- 型情報の追加
- import/export の解析
- 重み付け・優先度システムの導入
- 自動クリーンアップ機能
- 健全性レポート生成
- 中規模プロジェクト（5000ファイル）での検証

**成果物**:
- ベータ版
- ベンチマーク結果
- クリーンアップ効果測定レポート

### Phase 3: スケール対応（6ヶ月）

**目標**: 商用レベルの完成度

- 多言語対応（5言語以上）
- Index-chan（小型特化 LLM）の学習と統合
- インクリメンタル更新
- 並列化・最適化
- 大規模プロジェクト（10000ファイル以上）対応

**成果物**:
- 正式版リリース
- ドキュメント・API
- Index-chan モデル

## 8. リスクと対策

### リスク1: ベクトル検索の起点選定精度

**影響**: 起点が外れると、後続のグラフ探索も無意味になる

**対策**:
- トップk件（k=3〜5）を取得し、複数起点でカバー
- 関数単位 + docstring で埋め込み精度を向上
- ユーザーが起点を手動指定できるフォールバック機能

### リスク2: 大規模コードに対する性能問題

**影響**: 解析・検索に時間がかかり、実用性が低下

**対策**:
- Rust による並列化
- インクリメンタル更新（変更ファイルのみ再解析）
- オンデマンド解析（必要な部分のみ）

### リスク3: 依存グラフの爆発

**影響**: 探索範囲が広がりすぎてコンテキストが肥大化

**対策**:
- 最大ホップ数の制限（呼び出し先2、呼び出し元1）
- トークン数による打ち切り
- 優先度の低いノードの削除

### リスク4: 多言語対応の解析精度

**影響**: 言語ごとに依存関係の抽出精度がばらつく

**対策**:
- tree-sitter をベースに逐次拡張
- 言語ごとのテストケース整備
- コミュニティからのフィードバック収集

## 9. 将来展望

### 短期（1年以内）

- 主要言語（TypeScript, Python, Rust, Go, Java）対応
- IDE プラグイン（VSCode, IntelliJ）
- CLI ツール提供
- 統合コンテキストベースの一括編集機能
- デッドコード検出と自動クリーンアップ
- コード健全性レポート機能

### 中期（2〜3年）

- Index-chan の高度化
  - リアルタイム監視と即座の警告
  - 技術的負債の定量評価と可視化
  - 自動リファクタリング提案
- 高度なリファクタリング支援
  - 関数名変更の影響範囲を自動検出・一括適用
  - 型変更の波及効果を追跡・修正
  - アーキテクチャ変更の影響分析
- コード構造の最適化提案
  - 依存が強い領域を自動的に単一ファイルに統合
  - 疎結合化の提案
- テストコード・ドキュメントの依存関係も含める
- チーム向けの共有インデックス機能

### 長期（3年以上）

- LLM が読みやすい「新しいコード構造」への自動変換
- "LLM 最適化プログラミング" という新しい開発パラダイムの創出
- コードベース全体の構造改善支援

## 10. ユースケース例

### 10.1 コード理解

```
クエリ: "ユーザー認証の処理を理解したい"
  ↓
システムが関連コードを統合コンテキストとして提示
  ↓
LLM が全体を見て説明を生成
```

### 10.2 リファクタリング

```
クエリ: "authenticateUser を verifyUser に変更"
  ↓
依存グラフで影響範囲を特定（10ファイル）
  ↓
統合コンテキスト化して LLM に渡す
  ↓
LLM が全ファイルの変更計画を生成
  ↓
一括マージ・適用（整合性保証）
```

### 10.3 バグ修正

```
クエリ: "null チェックが漏れている箇所を修正"
  ↓
関連する関数群を依存グラフで取得
  ↓
統合コンテキストで LLM が全体を分析
  ↓
複数ファイルにまたがる修正を一括適用
```

### 10.4 コードクリーンアップ

```
定期実行または手動実行
  ↓
Index-chan がコードベース全体をスキャン
  ↓
デッドコード、ゾンビコード、未使用 import を検出
  ↓
優先度付きクリーンアップリストを生成
  ↓
ユーザー確認後、安全なものから自動削除
  ↓
結果レポート: "548行削減、技術的負債 12% 改善"
```

## 11. まとめ

本企画は、ベクトル検索とグラフ探索を組み合わせることで、LLM 向けコード検索の精度と効率を飛躍的に向上させる。

さらに、統合コンテキストによる一括編集機能により、従来のファイル単位の編集では困難だった「整合性の高い大規模リファクタリング」を実現する。これは単なる検索ツールではなく、LLM を活用した次世代の開発支援システムである。

従来の全文検索やベクトル検索を超え、構造的理解を前提とした「次世代のコード検索・編集」を実現する。技術的にも市場的にも高い価値を有し、LLM 時代の開発ツールとして大きな可能性を秘めている。

まずは MVP で小規模検証を行い、精度とパフォーマンスを確認した上で、段階的にスケールアップしていく戦略が現実的である。
