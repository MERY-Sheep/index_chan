# Index Librorum Prohibitorum - MVP ロードマップ

## 基本方針

- 企画書・設計書は「ビジョン」として保持
- このドキュメントで実際の開発計画を管理
- 段階的に価値を提供し、学びながら進化

---

## Phase 1: デッドコード検出CLI（2ヶ月）

### 目標
**即座に価値を提供できる最小機能**

### 実装内容

**コア機能**
├─ Rust + Tree-sitter による AST 解析
├─ 依存グラフ構築（関数呼び出しのみ）
├─ 使われていない関数・クラスの検出
├─ 安全性レベル評価（確実/おそらく安全/要確認）
└─ CLI ツール

**対応言語**
- TypeScript のみ（需要が高く、解析しやすい）

### 進捗状況（2024-12-02更新）

**完了 ✅**
├─ プロジェクト構造
├─ tree-sitterによるTypeScript解析
├─ ファイル走査とグラフ構築
├─ 依存関係の追跡
├─ デッドコード検出アルゴリズム
└─ レポート生成機能（コンソール/JSON）

**次のステップ**
├─ Phase 1.5: LLM統合（新規追加）
└─ Phase 2: 検索 + 会話グラフ基礎

**出力例**
```bash
$ index-chan scan ./src

🔍 デッドコード検出結果
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

🗑️  未使用関数: 12個 (234行)

[確実に安全]
├─ src/old-auth.ts:45-78 (oldAuthMethod)
├─ src/utils.ts:123-145 (deprecatedHelper)
└─ src/legacy.ts:1-234 (ファイル全体)

[おそらく安全]
├─ src/logger.ts:34-38 (emptyLogger)
└─ src/wrapper.ts:12-15 (simpleWrapper)

[要確認]
├─ src/api.ts:89-102 (unusedEndpoint)
└─ src/config.ts:56-67 (oldConfig)

💾 削減可能な行数: 234行 (全体の 8%)

削除しますか? (y/n/選択)
```

### 技術スタック

**言語・フレームワーク**
├─ Rust（パフォーマンスと安全性）
├─ tree-sitter（AST解析）
└─ clap（CLI構築）

**依存グラフ**
├─ petgraph（グラフデータ構造）
└─ メモリ内グラフ（永続化は後回し）

### 成果物

**リリース**
├─ index-chan CLI v0.1.0
├─ TypeScript 対応
└─ デッドコード検出・削除機能

**ドキュメント**
├─ README（使い方）
├─ 精度評価レポート
└─ 技術ドキュメント

### 成功指標

**定量**
├─ 検出精度: 90% 以上
├─ 誤検出率: 5% 以下
├─ 実行時間: 1000ファイルで 10秒以内
└─ 削減効果: 平均 5〜10%

**定性**
├─ 実際のプロジェクトで使える
├─ 誤削除のリスクが低い
└─ 開発者が安心して使える

### リスクと対策

**リスク1: 動的呼び出しの見落とし**
├─ 影響: 実際は使われているのに削除してしまう
└─ 対策: 保守的に判定、ユーザーに確認を促す

**リスク2: TypeScript特有の複雑さ**
├─ 影響: 型システムの解析が難しい
└─ 対策: 最初は関数呼び出しのみ、型は Phase 2

---

## Phase 1.5: LLM統合（2週間）

### 目標
**LLMによる高精度な判断と多言語対応の自動化**

### 実装内容

**LLMによるコード分析**
├─ コンテキスト収集（コード、コメント、git履歴）
├─ 削除可否の自動判定
├─ 判断理由の自然言語説明
└─ 確信度スコア（0-100%）

**多言語対応の自動化**
├─ LLMによる言語文法の学習
├─ 設定ファイルの自動生成
├─ `index-chan add-language <言語名>` コマンド
└─ ユーザーが自分で言語追加可能

**判断の高度化**
├─ 「将来使う予定」の検出
├─ 実験的機能の識別
├─ 古いコード vs 新しいコードの判別
└─ プロジェクトコンテキストの理解

### 技術スタック

**LLM統合**
├─ Candle（Rust製ML推論フレームワーク）
├─ Qwen2.5-Coder-1.5B-Instruct（ローカルLLM）
├─ モデル切り替え可能な設計
└─ プロンプトエンジニアリング

**モデル選択肢**
├─ Qwen2.5-Coder-1.5B（デフォルト、メモリ2-3GB）
├─ Qwen2.5-Coder-7B（高精度、メモリ8-10GB）
└─ 将来的に他モデルも追加可能

**コンテキスト収集**
├─ git2（git履歴の取得）
├─ コメント解析
└─ プロジェクト構造の理解

### 成果物

**リリース**
├─ index-chan CLI v0.1.5
├─ LLM統合機能
├─ 多言語追加コマンド
└─ 高精度な判定

**ドキュメント**
├─ LLM統合ガイド
├─ 新言語追加ガイド
└─ プロンプト設計ドキュメント

### 成功指標

**精度向上**
├─ 誤検出率: 5% → 1%以下
├─ 「将来使う予定」の検出精度: 80%以上
└─ ユーザー満足度: 大幅向上

**多言語対応**
├─ 新言語追加時間: 数日 → 30分
├─ 対応可能言語数: 無制限
└─ ユーザーによる言語追加: 可能

**コスト**
├─ API料金: ゼロ（完全ローカル）
├─ プライバシー: コードが外部に送信されない
├─ 初回ダウンロード: 約1GB
└─ メモリ使用量: 2-3GB（1.5Bモデル）

### 実装例

**使用例**
```bash
# 初回起動（モデルダウンロード）
$ index-chan scan ./src --llm

📥 初回起動: Qwen2.5-Coder-1.5Bをダウンロード中...
✅ モデル読み込み完了

🤖 LLMで分析中...
✅ 12個の未使用関数を検出

[削除推奨] 8個（確信度 95%以上）
├─ oldAuthMethod: 2年前に作成、新実装に置き換え済み
└─ deprecatedHelper: コミットログに「deprecated」

[保持推奨] 4個（確信度 85%以上）
├─ futureFeature: 1週間前に追加、WIP状態
└─ experimentalAI: 実験的機能、issue #123で議論中

# モデルを変更
$ index-chan config set llm.model "Qwen2.5-Coder-7B"
✅ モデルを変更しました（次回起動時に適用）

# 新言語を追加
$ index-chan add-language python

🤖 LLMに問い合わせ中...
✅ Python の文法情報を取得
📝 設定ファイルを生成: languages/python.json
✅ Python対応が完了しました！

$ index-chan scan ./python_project --language python
```

### 実装スケジュール

**Week 1: Candle + Qwen統合** ✅
├─ Candle依存関係の追加
├─ Qwen2.5-Coder-1.5Bの統合
├─ モデルダウンロード・キャッシュ機構
├─ 基本的な推論パイプライン
└─ 動作確認

**Week 2: 分析機能とCLI統合** ✅ 完了
├─ ✅ プロンプト設計
├─ ✅ JSON解析の堅牢化
├─ ✅ 削除可否判定ロジック
├─ ✅ CLI統合（scan --llm, annotate --llm）
├─ ✅ 自動アノテーション機能
├─ ✅ LLM推論の実機テスト（Codexの支援により成功）
├─ ✅ test-llmコマンド実装
└─ 📋 コンテキスト収集の強化（Phase 2へ延期）
└─ 📋 設定ファイル対応（Phase 2へ延期）

**Phase 1.5完了** 🎉
├─ 完了日: 2024-12-02
├─ 主な成果: LLM推論の実装と動作確認
├─ 技術的ブレークスルー: ModelForCausalLMによる推論成功
└─ 詳細: `Doc/MVP/Phase1.5_最終報告.md`参照

---

## Phase 2: 検索 + 会話グラフ基礎（3ヶ月）

### 目標
**Index-chanを「記憶を持つ司書」に進化させる**

### 実装内容

**コード検索機能**
├─ ベクトル検索（関数・クラス単位）
├─ 依存グラフベースの関連コード取得
├─ スマートコンテキスト生成
└─ VSCode 拡張（オプション）

**会話グラフ基礎**
├─ 会話履歴のグラフ化
├─ トピック自動検出
├─ 関連する過去の会話を抽出
├─ トークン数削減（40〜60%目標）
└─ 会話分析CLI（`index-chan analyze`）

**対応言語拡大**
├─ Python 追加
└─ 多言語対応の基盤整備

### 技術スタック

**ベクトル検索**
├─ Qdrant または Faiss
├─ OpenAI Embeddings または ローカルモデル
└─ インクリメンタル更新

**会話グラフ**
├─ 既存の依存グラフ技術を流用
├─ クラスタリング（DBSCAN）
└─ 小型LLMによるトピック推定（オプション）

### 成果物

**リリース**
├─ index-chan CLI v0.2.0
├─ コード検索機能
├─ 会話グラフ機能
├─ TypeScript + Python 対応
└─ VSCode 拡張（オプション）

**ドキュメント**
├─ 検索精度評価レポート
├─ トークン削減効果レポート
└─ API ドキュメント

### 成功指標

**コード検索**
├─ 検索精度: 80% 以上
├─ コンテキストサイズ削減: 40% 以上
└─ 検索時間: 1秒以内

**会話グラフ**
├─ トークン削減: 40〜60%
├─ トピック検出精度: 85% 以上
└─ ユーザー満足度: 高い

### Phase 2 完了後の判断ポイント

**次のステップを決める材料**
├─ ユーザーフィードバック
├─ 技術的な課題と可能性
├─ 市場の反応
├─ チームの状況
└─ 資金状況

**Phase 3 の選択肢**
1. 編集機能（会話グラフを活用）
2. 多言語対応の拡大
3. Index-chan（小型LLM）の学習
4. エンタープライズ機能
5. その他（市場の声を聞いて決定）

---

## Phase 3: TBD（Phase 2 完了後に決定）

### 判断基準

**編集機能を選ぶ場合**
├─ ユーザーから強い要望がある
├─ 会話グラフとの統合が技術的に実現可能
├─ 競合との差別化になる
└─ リソースが十分にある

**他の方向を選ぶ場合**
├─ 市場の反応が予想と異なる
├─ 技術的な制約がある
├─ より価値の高い機能が見つかる
└─ ピボットが必要

### 暫定案（参考）

**Phase 3a: 会話グラフの完成（2ヶ月）**
├─ 会話の要約
├─ 自動クリーンアップ
├─ トピック可視化
└─ 記憶の階層化

**Phase 3b: 編集機能（3ヶ月）**
├─ 会話履歴を理解した編集
├─ 統合コンテキスト編集
├─ 差分適用・ロールバック
└─ 外部LLM連携

**または別の方向**
├─ Index-chan（小型LLM）の実装
├─ エンタープライズ向け機能
├─ IDE統合の強化
└─ その他

---

## 開発原則

### 段階的な価値提供
- 各Phaseで独立した価値を提供
- 早期にユーザーフィードバックを得る
- 学びながら方向修正

### 技術的負債の最小化
- 最初から品質を重視
- リファクタリングを恐れない
- ドキュメントを常に更新

### 柔軟性の確保
- 計画に固執しない
- 市場の声を聞く
- ピボットの準備

---

## 更新履歴

- 2025-12-02: 初版作成
  - Phase 1, 2 を確定
  - Phase 3 は後日決定とする
- 2025-12-02: Phase 1.5 追加
  - LLM統合による高精度判定
  - 多言語対応の自動化
  - Phase 1 基本機能完了を反映
