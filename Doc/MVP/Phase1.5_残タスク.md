# Phase 1.5 残タスク

**更新日**: 2024-12-02（LLM推論テスト成功を反映）

---

## 優先度高（Week 2完了前）

### 1. LLM推論の実機テスト ✅ 完了

**目的**: 実際にモデルをダウンロードして推論が動作するか確認

**タスク**
- [x] モデルダウンロードの動作確認
- [x] 推論の動作確認
- [x] トークナイザーの動作確認
- [x] 日本語応答の生成確認

**テスト結果**
```bash
$ cargo run --release -- test-llm
✅ 推論成功！

📤 応答:
この関数は削除しても安全です。JavaScript では、関数はスコープ内に存在し、
関数の定義はそのスコープの外に存在します。つまり、関数はスコープ外
```

**確認事項**
- ✅ ModelForCausalLMへの修正により推論が正常動作
- ✅ 意味のある日本語応答を生成
- ✅ EOSトークンの正しい検出
- ✅ コード分析タスクに適した応答品質

**詳細**: `Doc/調査/LLM推論_実機テスト結果.md`参照

---

### 2. プロンプトの最適化 🎯

**目的**: LLMの出力品質を向上させる

**現状**: 基本的なプロンプトは実装済み

**今後の改善タスク**
- [ ] 実際のプロジェクトでの精度検証
  - JSON形式が正しいか
  - 理由が適切か
  - カテゴリ分類が正確か
- [ ] Few-shot例の追加検討
  ```
  Example 1:
  Function: oldAuthMethod
  Context: Replaced 2 years ago
  Output: {"should_delete": true, "confidence": 0.95, ...}
  
  Example 2:
  Function: experimentalFeature
  Context: Added 1 week ago, marked as WIP
  Output: {"should_delete": false, "confidence": 0.90, ...}
  ```
- [ ] エッジケースへの対応
  - 複雑なコンテキスト
  - 判断が難しいケース
  - 多言語対応

**評価基準**
- JSON解析成功率: 95%以上
- カテゴリ分類精度: 85%以上
- 理由の妥当性: 人間が納得できる

---

### 3. ドキュメント更新 📝

**目的**: ユーザーが使えるようにする

**完了タスク**
- [x] README.md更新
  - LLMモードの説明追加
  - 使用例の追加
  - システム要件の記載
- [x] Phase1.5_Week2_進捗報告.md作成
- [x] LLM推論_実機テスト結果.md更新
  - Codexの修正内容を反映
  - 成功事例を追加
  - 技術的知見を整理

**今後のタスク**
- [ ] トラブルシューティングガイド作成
  - よくあるエラーと対処法
  - パフォーマンスチューニング
  - モデル選択のガイド
- [ ] 使用例の充実
  - 実際のプロジェクトでの使用例
  - スクリーンショット
  - ビフォー・アフター
- [ ] Phase1.5完了報告書の作成

---

## 優先度中（Phase 1.5完了前）

### 4. コンテキスト収集の強化 📊

**目的**: LLMにより良い情報を提供する

**タスク**
- [ ] コメント解析の追加
  ```rust
  // TODO: 将来使う予定
  // FIXME: バグあり
  // @deprecated
  ```
- [ ] Git履歴の詳細分析
  - 最終更新日時
  - コミット頻度
  - コミットメッセージの内容
- [ ] プロジェクト構造の理解
  - ディレクトリ構造
  - ファイル間の関係
  - モジュールの役割

**実装例**
```rust
pub struct EnhancedContext {
    pub file_info: FileInfo,
    pub git_history: GitHistory,
    pub comments: Vec<Comment>,
    pub project_structure: ProjectStructure,
}
```

---

### 5. エラーハンドリング改善 🛡️

**目的**: ユーザーフレンドリーなエラーメッセージ

**タスク**
- [ ] ネットワークエラー対応
  ```
  ❌ モデルのダウンロードに失敗しました
  
  原因: ネットワーク接続エラー
  対処法:
  1. インターネット接続を確認してください
  2. プロキシ設定を確認してください
  3. 手動でモデルをダウンロードできます:
     https://huggingface.co/Qwen/Qwen2.5-Coder-1.5B-Instruct
  ```
- [ ] モデルロードエラー対応
  ```
  ❌ モデルの読み込みに失敗しました
  
  原因: メモリ不足
  対処法:
  1. 他のアプリケーションを閉じてください
  2. より小さいモデルを使用してください:
     index-chan config set llm.model "smaller-model"
  ```
- [ ] 推論エラー対応
  ```
  ⚠️  一部の関数の分析に失敗しました (2/10)
  
  失敗した関数:
  - complexFunction: トークン数が多すぎます
  - strangeFunction: 解析エラー
  
  これらの関数は通常モードで分析されました
  ```

---

### 6. 精度評価 📈

**目的**: LLMの判定精度を測定する

**タスク**
- [ ] テストデータセットの作成
  - 削除すべきコード: 20個
  - 保持すべきコード: 20個
  - 判断が難しいコード: 10個
- [ ] 精度測定
  - 正解率
  - 誤検出率（False Positive）
  - 見落とし率（False Negative）
  - 確信度スコアの妥当性
- [ ] レポート作成
  ```
  精度評価レポート
  
  総テストケース: 50個
  正解: 45個 (90%)
  誤検出: 3個 (6%)
  見落とし: 2個 (4%)
  
  カテゴリ別精度:
  - SafeToDelete: 95%
  - KeepForFuture: 85%
  - Experimental: 80%
  ```

---

## 優先度低（Phase 2以降）

### 7. 設定ファイル対応 ⚙️

**目的**: ユーザーがカスタマイズできるようにする

**タスク**
- [ ] .index-chan/config.json
  ```json
  {
    "llm": {
      "model": "Qwen/Qwen2.5-Coder-1.5B-Instruct",
      "temperature": 0.7,
      "max_tokens": 512,
      "confidence_threshold": 0.85
    }
  }
  ```
- [ ] 設定コマンド実装
  ```bash
  # 設定確認
  index-chan config show
  
  # 設定変更
  index-chan config set llm.model "Qwen/Qwen2.5-Coder-7B-Instruct"
  index-chan config set llm.confidence_threshold 0.9
  ```
- [ ] モデル選択機能
  - 1.5Bモデル（デフォルト）
  - 7Bモデル（高精度）
  - カスタムモデル

---

### 8. パフォーマンス最適化 ⚡

**目的**: 大規模プロジェクトでも快適に使える

**タスク**
- [ ] バッチ処理
  - 複数の関数をまとめて分析
  - プロンプトの効率化
- [ ] キャッシュ活用
  - 分析結果のキャッシュ
  - ファイルハッシュによる差分検出
- [ ] 並列処理
  - 複数ファイルの並列スキャン
  - 推論の並列実行（将来）
- [ ] モデルの量子化
  - メモリ使用量削減
  - 推論速度向上

**目標**
- 100ファイル: 5分以内
- 1000ファイル: 30分以内
- メモリ使用量: 3GB以下

---

### 9. 多言語対応の自動化 🌐

**目的**: ユーザーが自分で言語を追加できる

**タスク**
- [ ] add-language コマンド実装
  ```bash
  index-chan add-language python
  
  🤖 LLMに問い合わせ中...
  ✅ Python の文法情報を取得
  📝 設定ファイルを生成: languages/python.json
  ✅ Python対応が完了しました！
  ```
- [ ] 言語設定ファイルの自動生成
  ```json
  {
    "name": "python",
    "extensions": [".py"],
    "tree_sitter_grammar": "python",
    "annotation_format": "# noqa: F841 - index-chan: {reason}"
  }
  ```
- [ ] LLMによる文法学習
  - 関数定義の検出方法
  - 関数呼び出しの検出方法
  - エクスポートの判定方法

---

## タイムライン

### ✅ 完了（2024-12-02）
1. LLM推論の実機テスト
2. 基本的なドキュメント更新

### 今週中（Phase 1.5完了）
3. プロンプトの最適化（実プロジェクトでの検証）
4. コンテキスト収集の強化
5. エラーハンドリング改善
6. 精度評価
7. Phase1.5完了報告書の作成

### Phase 2以降
8. 設定ファイル対応
9. パフォーマンス最適化
10. 多言語対応の自動化

---

## 成功基準

### Phase 1.5完了の定義

**必須** ✅ 達成
- [x] LLMモジュール実装完了
- [x] CLI統合完了
- [x] 自動アノテーション機能実装
- [x] LLM推論の動作確認（Codexの修正により成功）
- [x] 基本的なドキュメント整備

**推奨** 🚧 進行中
- [ ] プロンプト最適化（実プロジェクトでの検証）
- [ ] エラーハンドリング改善
- [ ] 精度評価レポート
- [ ] Phase1.5完了報告書

**オプション** 📅 Phase 2以降
- [ ] 設定ファイル対応
- [ ] パフォーマンス最適化
- [ ] 多言語対応の自動化

---

## 更新履歴

- 2025-12-02: 初版作成
