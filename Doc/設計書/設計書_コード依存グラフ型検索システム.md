# ã‚³ãƒ¼ãƒ‰ä¾å­˜ã‚°ãƒ©ãƒ•å‹æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ  è¨­è¨ˆæ›¸

## 1. ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### 1.1 å…¨ä½“æ§‹æˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              LLM ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹å±¤               â”‚
â”‚  (è‡ªç„¶è¨€èªã‚¯ã‚¨ãƒªå—ä»˜ / ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæä¾›)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              æ¤œç´¢ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å±¤            â”‚
â”‚  (ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ + ã‚°ãƒ©ãƒ•æ¢ç´¢ã®çµ±åˆåˆ¶å¾¡)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ â”‚          â”‚ ã‚°ãƒ©ãƒ•æ¢ç´¢ã‚¨ãƒ³ã‚¸ãƒ³ â”‚
â”‚  (èµ·ç‚¹ç‰¹å®š)        â”‚          â”‚  (ä¾å­˜é–¢ä¿‚è¿½è·¡)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å±¤                     â”‚
â”‚  (ãƒ™ã‚¯ãƒˆãƒ«DB / ä¾å­˜ã‚°ãƒ©ãƒ•DB)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                è§£æãƒ»æ§‹ç¯‰å±¤                       â”‚
â”‚  (tree-sitter / ASTè§£æ / ã‚°ãƒ©ãƒ•æ§‹ç¯‰)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯

**ã‚³ã‚¢å®Ÿè£…**
- è¨€èª: Rust
- ç†ç”±: é«˜é€Ÿæ€§ã€ãƒ¡ãƒ¢ãƒªå®‰å…¨æ€§ã€ä¸¦åˆ—å‡¦ç†ã®å®¹æ˜“ã•

**è§£æåŸºç›¤**
- tree-sitter: å¤šè¨€èªãƒ‘ãƒ¼ã‚µãƒ¼
- å„è¨€èªã® tree-sitter grammar

**ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢**
- Qdrant ã¾ãŸã¯ Milvus: ãƒ™ã‚¯ãƒˆãƒ«DB
- sentence-transformers: åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ï¼ˆCodeBERT, GraphCodeBERT ãªã©ï¼‰

**ã‚°ãƒ©ãƒ•å‡¦ç†**
- petgraph: Rust ã®ã‚°ãƒ©ãƒ•ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
- æ°¸ç¶šåŒ–: RocksDB ã¾ãŸã¯ SQLite

**API/CLI**
- axum: Web ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ï¼ˆREST APIï¼‰
- clap: CLI ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯

## 2. ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«

### 2.1 ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£

```rust
// ãƒãƒ¼ãƒ‰ã®ç¨®é¡
enum NodeType {
    Function,
    Class,
    Method,
    Interface,
    Type,
    Module,
    File,
}

// ã‚³ãƒ¼ãƒ‰ãƒãƒ¼ãƒ‰
struct CodeNode {
    id: String,              // ä¸€æ„è­˜åˆ¥å­
    node_type: NodeType,     // ãƒãƒ¼ãƒ‰ç¨®åˆ¥
    name: String,            // é–¢æ•°å/ã‚¯ãƒ©ã‚¹åãªã©
    file_path: String,       // ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    start_line: u32,         // é–‹å§‹è¡Œ
    end_line: u32,           // çµ‚äº†è¡Œ
    signature: String,       // é–¢æ•°ã‚·ã‚°ãƒãƒãƒ£ãªã©
    docstring: Option<String>, // ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
    code_snippet: String,    // ã‚³ãƒ¼ãƒ‰æœ¬ä½“
    embedding: Vec<f32>,     // ãƒ™ã‚¯ãƒˆãƒ«åŸ‹ã‚è¾¼ã¿
}
```

### 2.2 ä¾å­˜é–¢ä¿‚ã‚¨ãƒƒã‚¸

```rust
// ã‚¨ãƒƒã‚¸ã®ç¨®é¡
enum EdgeType {
    Calls,          // é–¢æ•°å‘¼ã³å‡ºã—
    CalledBy,       // å‘¼ã³å‡ºã•ã‚Œã‚‹
    References,     // å‚ç…§
    Implements,     // å®Ÿè£…
    Extends,        // ç¶™æ‰¿
    Imports,        // ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    TypeOf,         // å‹é–¢ä¿‚
}

// ä¾å­˜é–¢ä¿‚ã‚¨ãƒƒã‚¸
struct DependencyEdge {
    from_node: String,       // èµ·ç‚¹ãƒãƒ¼ãƒ‰ID
    to_node: String,         // çµ‚ç‚¹ãƒãƒ¼ãƒ‰ID
    edge_type: EdgeType,     // ã‚¨ãƒƒã‚¸ç¨®åˆ¥
    weight: f32,             // é‡ã¿ï¼ˆå„ªå…ˆåº¦è¨ˆç®—ç”¨ï¼‰
}
```

### 2.3 ä¾å­˜ã‚°ãƒ©ãƒ•

```rust
struct DependencyGraph {
    nodes: HashMap<String, CodeNode>,
    edges: Vec<DependencyEdge>,
    adjacency_list: HashMap<String, Vec<String>>, // é«˜é€Ÿæ¢ç´¢ç”¨
}
```

## 3. ã‚³ã‚¢æ©Ÿèƒ½ã®è©³ç´°è¨­è¨ˆ

### 3.1 è§£æãƒ»ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰

#### 3.1.1 ã‚³ãƒ¼ãƒ‰è§£æãƒ•ãƒ­ãƒ¼

```
1. ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
   â†“
2. tree-sitter ã§ãƒ‘ãƒ¼ã‚¹ â†’ AST ç”Ÿæˆ
   â†“
3. AST ãƒˆãƒ©ãƒãƒ¼ã‚¹
   - é–¢æ•°/ã‚¯ãƒ©ã‚¹å®šç¾©ã®æŠ½å‡º
   - å‘¼ã³å‡ºã—é–¢ä¿‚ã®æŠ½å‡º
   - import/export ã®æŠ½å‡º
   â†“
4. CodeNode ç”Ÿæˆ
   â†“
5. åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆ
   - é–¢æ•°å + ã‚·ã‚°ãƒãƒãƒ£ + docstring ã‚’çµåˆ
   - CodeBERT ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
   â†“
6. ãƒ™ã‚¯ãƒˆãƒ«DB ã«ä¿å­˜
```

#### 3.1.2 ä¾å­˜ã‚°ãƒ©ãƒ•æ§‹ç¯‰

```rust
fn build_dependency_graph(files: Vec<FilePath>) -> DependencyGraph {
    let mut graph = DependencyGraph::new();
    
    // Phase 1: ãƒãƒ¼ãƒ‰æŠ½å‡º
    for file in files {
        let ast = parse_file(file);
        let nodes = extract_nodes(ast);
        graph.add_nodes(nodes);
    }
    
    // Phase 2: ã‚¨ãƒƒã‚¸æ§‹ç¯‰
    for file in files {
        let ast = parse_file(file);
        let edges = extract_dependencies(ast, &graph.nodes);
        graph.add_edges(edges);
    }
    
    // Phase 3: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰
    graph.build_adjacency_list();
    
    graph
}
```

#### 3.1.3 ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ã‚¿ãƒ«æ›´æ–°

```rust
fn incremental_update(graph: &mut DependencyGraph, changed_files: Vec<FilePath>) {
    // å¤‰æ›´ãƒ•ã‚¡ã‚¤ãƒ«ã«é–¢é€£ã™ã‚‹ãƒãƒ¼ãƒ‰ãƒ»ã‚¨ãƒƒã‚¸ã‚’å‰Šé™¤
    for file in &changed_files {
        graph.remove_nodes_by_file(file);
        graph.remove_edges_by_file(file);
    }
    
    // å†è§£æã—ã¦è¿½åŠ 
    for file in changed_files {
        let ast = parse_file(file);
        let nodes = extract_nodes(ast);
        let edges = extract_dependencies(ast, &graph.nodes);
        graph.add_nodes(nodes);
        graph.add_edges(edges);
    }
    
    // ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†æ§‹ç¯‰
    graph.rebuild_adjacency_list();
}
```

### 3.2 ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢

#### 3.2.1 æ¤œç´¢ãƒ•ãƒ­ãƒ¼å…¨ä½“

```rust
struct SearchRequest {
    query: String,           // è‡ªç„¶è¨€èªã‚¯ã‚¨ãƒª
    top_k: usize,           // èµ·ç‚¹å€™è£œæ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 3ï¼‰
    max_hops_forward: usize, // å‘¼ã³å‡ºã—å…ˆã®æœ€å¤§ãƒ›ãƒƒãƒ—æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 2ï¼‰
    max_hops_backward: usize,// å‘¼ã³å‡ºã—å…ƒã®æœ€å¤§ãƒ›ãƒƒãƒ—æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1ï¼‰
    max_tokens: usize,      // æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 8000ï¼‰
}

struct SearchResult {
    contexts: Vec<ContextGroup>, // èµ·ç‚¹ã”ã¨ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
    total_tokens: usize,
}

struct ContextGroup {
    anchor_node: CodeNode,       // èµ·ç‚¹ãƒãƒ¼ãƒ‰
    related_nodes: Vec<CodeNode>, // é–¢é€£ãƒãƒ¼ãƒ‰ï¼ˆå„ªå…ˆåº¦é †ï¼‰
    relevance_score: f32,        // èµ·ç‚¹ã®é–¢é€£åº¦ã‚¹ã‚³ã‚¢
}
```

#### 3.2.2 ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã«ã‚ˆã‚‹èµ·ç‚¹ç‰¹å®š

```rust
fn find_anchor_nodes(query: &str, top_k: usize) -> Vec<(CodeNode, f32)> {
    // 1. ã‚¯ã‚¨ãƒªã‚’åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›
    let query_embedding = encode_query(query);
    
    // 2. ãƒ™ã‚¯ãƒˆãƒ«DB ã§é¡ä¼¼æ¤œç´¢
    let results = vector_db.search(query_embedding, top_k);
    
    // 3. ã‚¹ã‚³ã‚¢ä»˜ãã§è¿”ã™
    results.into_iter()
        .map(|(node_id, score)| {
            let node = graph.get_node(node_id);
            (node, score)
        })
        .collect()
}
```

#### 3.2.3 ä¾å­˜ã‚°ãƒ©ãƒ•æ¢ç´¢

```rust
fn explore_dependencies(
    graph: &DependencyGraph,
    anchor: &CodeNode,
    max_hops_forward: usize,
    max_hops_backward: usize,
) -> Vec<CodeNode> {
    let mut visited = HashSet::new();
    let mut result = Vec::new();
    
    // èµ·ç‚¹è‡ªèº«ã‚’è¿½åŠ 
    result.push(anchor.clone());
    visited.insert(anchor.id.clone());
    
    // å‘¼ã³å‡ºã—å…ˆæ–¹å‘ã®æ¢ç´¢ï¼ˆBFSï¼‰
    let forward_nodes = bfs_forward(
        graph,
        &anchor.id,
        max_hops_forward,
        &mut visited
    );
    result.extend(forward_nodes);
    
    // å‘¼ã³å‡ºã—å…ƒæ–¹å‘ã®æ¢ç´¢ï¼ˆBFSï¼‰
    let backward_nodes = bfs_backward(
        graph,
        &anchor.id,
        max_hops_backward,
        &mut visited
    );
    result.extend(backward_nodes);
    
    // å‹å®šç¾©ã®è¿½åŠ 
    let type_nodes = find_related_types(graph, &result);
    result.extend(type_nodes);
    
    result
}

fn bfs_forward(
    graph: &DependencyGraph,
    start: &str,
    max_hops: usize,
    visited: &mut HashSet<String>,
) -> Vec<CodeNode> {
    let mut queue = VecDeque::new();
    let mut result = Vec::new();
    
    queue.push_back((start.to_string(), 0));
    
    while let Some((node_id, depth)) = queue.pop_front() {
        if depth >= max_hops {
            continue;
        }
        
        // å‘¼ã³å‡ºã—å…ˆã‚’å–å¾—
        let callees = graph.get_callees(&node_id);
        
        for callee_id in callees {
            if visited.insert(callee_id.clone()) {
                let node = graph.get_node(&callee_id);
                result.push(node);
                queue.push_back((callee_id, depth + 1));
            }
        }
    }
    
    result
}
```

#### 3.2.4 å„ªå…ˆåº¦ä»˜ã‘ã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°

```rust
fn prioritize_nodes(nodes: Vec<CodeNode>, anchor: &CodeNode) -> Vec<CodeNode> {
    let mut scored_nodes: Vec<(CodeNode, f32)> = nodes
        .into_iter()
        .map(|node| {
            let score = calculate_priority(&node, anchor);
            (node, score)
        })
        .collect();
    
    // ã‚¹ã‚³ã‚¢é™é †ã§ã‚½ãƒ¼ãƒˆ
    scored_nodes.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap());
    
    scored_nodes.into_iter().map(|(node, _)| node).collect()
}

fn calculate_priority(node: &CodeNode, anchor: &CodeNode) -> f32 {
    let mut score = 0.0;
    
    // åŒä¸€ãƒ•ã‚¡ã‚¤ãƒ«: +10
    if node.file_path == anchor.file_path {
        score += 10.0;
    }
    
    // ç›´æ¥å‘¼ã³å‡ºã—: +5
    if is_direct_dependency(node, anchor) {
        score += 5.0;
    }
    
    // å‹å®šç¾©: +3
    if node.node_type == NodeType::Type || node.node_type == NodeType::Interface {
        score += 3.0;
    }
    
    // ã‚³ãƒ¼ãƒ‰ã‚µã‚¤ã‚ºãŒå°ã•ã„: +1
    let lines = node.end_line - node.start_line;
    if lines < 20 {
        score += 1.0;
    }
    
    score
}

fn filter_by_token_limit(nodes: Vec<CodeNode>, max_tokens: usize) -> Vec<CodeNode> {
    let mut result = Vec::new();
    let mut total_tokens = 0;
    
    for node in nodes {
        let tokens = estimate_tokens(&node.code_snippet);
        if total_tokens + tokens <= max_tokens {
            result.push(node);
            total_tokens += tokens;
        } else {
            break;
        }
    }
    
    result
}
```

#### 3.2.5 è¤‡æ•°èµ·ç‚¹ã®çµ±åˆ

```rust
fn merge_contexts(context_groups: Vec<ContextGroup>) -> SearchResult {
    // é‡è¤‡ãƒãƒ¼ãƒ‰ã®æ’é™¤ï¼ˆèµ·ç‚¹æƒ…å ±ã¯ä¿æŒï¼‰
    let mut node_map: HashMap<String, (CodeNode, Vec<String>)> = HashMap::new();
    
    for group in &context_groups {
        for node in &group.related_nodes {
            node_map
                .entry(node.id.clone())
                .or_insert_with(|| (node.clone(), Vec::new()))
                .1
                .push(group.anchor_node.id.clone());
        }
    }
    
    // èµ·ç‚¹ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã¦è¿”ã™
    SearchResult {
        contexts: context_groups,
        total_tokens: calculate_total_tokens(&context_groups),
    }
}
```

### 3.3 LLM ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹

#### 3.3.1 ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ

```rust
fn format_context_for_llm(result: SearchResult) -> String {
    let mut output = String::new();
    
    output.push_str("# æ¤œç´¢çµæœ\n\n");
    
    for (i, group) in result.contexts.iter().enumerate() {
        output.push_str(&format!("## èµ·ç‚¹ {}: {}\n", i + 1, group.anchor_node.name));
        output.push_str(&format!("é–¢é€£åº¦ã‚¹ã‚³ã‚¢: {:.2}\n\n", group.relevance_score));
        
        // èµ·ç‚¹ãƒãƒ¼ãƒ‰
        output.push_str("### èµ·ç‚¹ã‚³ãƒ¼ãƒ‰\n");
        output.push_str(&format_code_block(&group.anchor_node));
        output.push_str("\n");
        
        // é–¢é€£ãƒãƒ¼ãƒ‰
        output.push_str("### é–¢é€£ã‚³ãƒ¼ãƒ‰\n");
        for node in &group.related_nodes {
            output.push_str(&format_code_block(node));
            output.push_str("\n");
        }
    }
    
    output
}

fn format_code_block(node: &CodeNode) -> String {
    format!(
        "```\n// ãƒ•ã‚¡ã‚¤ãƒ«: {}\n// è¡Œ: {}-{}\n{}\n```\n",
        node.file_path,
        node.start_line,
        node.end_line,
        node.code_snippet
    )
}
```

## 4. çµ±åˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç·¨é›†ã‚·ã‚¹ãƒ†ãƒ 

### 4.1 ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```
è‡ªç„¶è¨€èªã‚¯ã‚¨ãƒªï¼ˆä¾‹: "é–¢æ•°åã‚’å¤‰æ›´"ï¼‰
  â†“
ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã§é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ç‰¹å®š
  â†“
çµ±åˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
  â†“
LLM ã«æ¸¡ã—ã¦å¤‰æ›´è¨ˆç”»ã‚’ç”Ÿæˆ
  â†“
å¤‰æ›´è¨ˆç”»ã‚’ãƒ‘ãƒ¼ã‚¹
  â†“
ä¸€æ‹¬ãƒãƒ¼ã‚¸ãƒ»é©ç”¨
```

### 4.2 ãƒ‡ãƒ¼ã‚¿æ§‹é€ 

```rust
// çµ±åˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
struct UnifiedContext {
    files: Vec<FileContext>,
    total_tokens: usize,
}

struct FileContext {
    path: String,
    content: String,
    nodes: Vec<CodeNode>,  // ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«å†…ã®ãƒãƒ¼ãƒ‰
}

// å¤‰æ›´è¨ˆç”»
struct ChangePlan {
    changes: Vec<FileChange>,
}

struct FileChange {
    file_path: String,
    edits: Vec<Edit>,
}

struct Edit {
    start_line: u32,
    end_line: u32,
    old_content: String,
    new_content: String,
    reason: String,  // å¤‰æ›´ç†ç”±
}
```

### 4.3 çµ±åˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ

```rust
fn create_unified_context(
    graph: &DependencyGraph,
    anchor_nodes: Vec<CodeNode>,
) -> UnifiedContext {
    let mut file_map: HashMap<String, Vec<CodeNode>> = HashMap::new();
    
    // èµ·ç‚¹ãƒãƒ¼ãƒ‰ã¨ãã®ä¾å­˜å…ˆã‚’åé›†
    for anchor in anchor_nodes {
        let related = explore_dependencies(graph, &anchor, 2, 1);
        
        for node in related {
            file_map
                .entry(node.file_path.clone())
                .or_insert_with(Vec::new)
                .push(node);
        }
    }
    
    // ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰
    let files: Vec<FileContext> = file_map
        .into_iter()
        .map(|(path, nodes)| {
            let content = read_file(&path);
            FileContext { path, content, nodes }
        })
        .collect();
    
    let total_tokens = files.iter()
        .map(|f| estimate_tokens(&f.content))
        .sum();
    
    UnifiedContext { files, total_tokens }
}

// LLM ç”¨ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
fn format_unified_context(context: &UnifiedContext) -> String {
    let mut output = String::new();
    
    output.push_str("# çµ±åˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ\n\n");
    output.push_str(&format!("ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {}\n", context.files.len()));
    output.push_str(&format!("ç·ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {}\n\n", context.total_tokens));
    
    for file in &context.files {
        output.push_str(&format!("## ãƒ•ã‚¡ã‚¤ãƒ«: {}\n\n", file.path));
        output.push_str("```\n");
        output.push_str(&file.content);
        output.push_str("\n```\n\n");
        
        // é‡è¦ãªãƒãƒ¼ãƒ‰ã‚’å¼·èª¿
        if !file.nodes.is_empty() {
            output.push_str("### é‡è¦ãªè¦ç´ \n");
            for node in &file.nodes {
                output.push_str(&format!("- {} (è¡Œ {}-{})\n", 
                    node.name, node.start_line, node.end_line));
            }
            output.push_str("\n");
        }
    }
    
    output
}
```

### 4.4 å¤‰æ›´è¨ˆç”»ã®ç”Ÿæˆã¨é©ç”¨

```rust
// LLM ã«å¤‰æ›´ã‚’ä¾é ¼
async fn generate_change_plan(
    context: &UnifiedContext,
    instruction: &str,
) -> ChangePlan {
    let prompt = format!(
        "{}\n\næŒ‡ç¤º: {}\n\nä»¥ä¸‹ã®å½¢å¼ã§å¤‰æ›´è¨ˆç”»ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„:\n\
        FILE: <ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹>\n\
        EDIT: <é–‹å§‹è¡Œ>-<çµ‚äº†è¡Œ>\n\
        OLD:\n<å¤ã„ã‚³ãƒ¼ãƒ‰>\n\
        NEW:\n<æ–°ã—ã„ã‚³ãƒ¼ãƒ‰>\n\
        REASON: <å¤‰æ›´ç†ç”±>\n",
        format_unified_context(context),
        instruction
    );
    
    let response = llm_client.complete(prompt).await;
    parse_change_plan(&response)
}

// å¤‰æ›´è¨ˆç”»ã®ãƒ‘ãƒ¼ã‚¹
fn parse_change_plan(llm_output: &str) -> ChangePlan {
    let mut changes = Vec::new();
    let mut current_file = None;
    let mut current_edit = None;
    
    for line in llm_output.lines() {
        if line.starts_with("FILE:") {
            if let Some(file) = current_file.take() {
                changes.push(file);
            }
            current_file = Some(FileChange {
                file_path: line[5..].trim().to_string(),
                edits: Vec::new(),
            });
        } else if line.starts_with("EDIT:") {
            // ãƒ‘ãƒ¼ã‚¹å‡¦ç†...
        }
        // ... ä»–ã®ãƒ‘ãƒ¼ã‚¹å‡¦ç†
    }
    
    if let Some(file) = current_file {
        changes.push(file);
    }
    
    ChangePlan { changes }
}

// å¤‰æ›´ã®ä¸€æ‹¬é©ç”¨
fn apply_change_plan(plan: ChangePlan) -> Result<(), Error> {
    // ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³çš„ã«é©ç”¨
    let mut backups = HashMap::new();
    
    // 1. ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
    for change in &plan.changes {
        let content = read_file(&change.file_path)?;
        backups.insert(change.file_path.clone(), content);
    }
    
    // 2. å¤‰æ›´é©ç”¨
    for change in &plan.changes {
        match apply_file_changes(&change.file_path, &change.edits) {
            Ok(_) => {},
            Err(e) => {
                // ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯
                for (path, content) in backups {
                    write_file(&path, &content)?;
                }
                return Err(e);
            }
        }
    }
    
    Ok(())
}

fn apply_file_changes(file_path: &str, edits: &[Edit]) -> Result<(), Error> {
    let content = read_file(file_path)?;
    let lines: Vec<&str> = content.lines().collect();
    let mut new_lines = Vec::new();
    
    let mut current_line = 0;
    
    for edit in edits {
        // å¤‰æ›´å‰ã®è¡Œã‚’ã‚³ãƒ”ãƒ¼
        new_lines.extend_from_slice(&lines[current_line..edit.start_line as usize]);
        
        // æ–°ã—ã„ã‚³ãƒ¼ãƒ‰ã‚’æŒ¿å…¥
        new_lines.extend(edit.new_content.lines());
        
        current_line = edit.end_line as usize;
    }
    
    // æ®‹ã‚Šã®è¡Œã‚’ã‚³ãƒ”ãƒ¼
    new_lines.extend_from_slice(&lines[current_line..]);
    
    write_file(file_path, &new_lines.join("\n"))
}
```

### 4.5 å¤‰æ›´ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã¨ç¢ºèª

```rust
// å¤‰æ›´å†…å®¹ã‚’ diff å½¢å¼ã§è¡¨ç¤º
fn preview_changes(plan: &ChangePlan) -> String {
    let mut output = String::new();
    
    for change in &plan.changes {
        output.push_str(&format!("\n=== {} ===\n", change.file_path));
        
        for edit in &change.edits {
            output.push_str(&format!("\n@@ è¡Œ {}-{} @@\n", 
                edit.start_line, edit.end_line));
            
            // å‰Šé™¤è¡Œ
            for line in edit.old_content.lines() {
                output.push_str(&format!("- {}\n", line));
            }
            
            // è¿½åŠ è¡Œ
            for line in edit.new_content.lines() {
                output.push_str(&format!("+ {}\n", line));
            }
            
            output.push_str(&format!("\nç†ç”±: {}\n", edit.reason));
        }
    }
    
    output
}

// ãƒ¦ãƒ¼ã‚¶ãƒ¼ç¢ºèª
fn confirm_and_apply(plan: ChangePlan) -> Result<(), Error> {
    println!("{}", preview_changes(&plan));
    println!("\nå¤‰æ›´ã‚’é©ç”¨ã—ã¾ã™ã‹? (y/n): ");
    
    let mut input = String::new();
    std::io::stdin().read_line(&mut input)?;
    
    if input.trim().to_lowercase() == "y" {
        apply_change_plan(plan)?;
        println!("å¤‰æ›´ã‚’é©ç”¨ã—ã¾ã—ãŸ");
    } else {
        println!("å¤‰æ›´ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ");
    }
    
    Ok(())
}
```

## 5. API è¨­è¨ˆ

### 5.1 REST API

```rust
// æ¤œç´¢ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
POST /api/search
Request:
{
    "query": "ãƒ¦ãƒ¼ã‚¶ãƒ¼èªè¨¼ã®å‡¦ç†",
    "top_k": 3,
    "max_hops_forward": 2,
    "max_hops_backward": 1,
    "max_tokens": 8000
}

Response:
{
    "contexts": [
        {
            "anchor_node": {
                "id": "func_123",
                "name": "authenticateUser",
                "file_path": "src/auth.ts",
                "code_snippet": "...",
                ...
            },
            "related_nodes": [...],
            "relevance_score": 0.92
        }
    ],
    "total_tokens": 6543
}

// çµ±åˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç·¨é›†
POST /api/edit
Request:
{
    "query": "authenticateUser ã‚’ verifyUser ã«å¤‰æ›´",
    "top_k": 3,
    "preview_only": false  // true ã®å ´åˆã¯é©ç”¨ã›ãšãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ã¿
}

Response:
{
    "change_plan": {
        "changes": [
            {
                "file_path": "src/auth.ts",
                "edits": [
                    {
                        "start_line": 45,
                        "end_line": 45,
                        "old_content": "function authenticateUser()",
                        "new_content": "function verifyUser()",
                        "reason": "é–¢æ•°åã®å¤‰æ›´"
                    }
                ]
            }
        ]
    },
    "preview": "=== src/auth.ts ===\n- function authenticateUser()\n+ function verifyUser()\n...",
    "affected_files": 4
}

// ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰
POST /api/index/build
Request:
{
    "project_path": "/path/to/project",
    "languages": ["typescript", "python"]
}

// ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ã‚¿ãƒ«æ›´æ–°
POST /api/index/update
Request:
{
    "changed_files": ["src/auth.ts", "src/user.ts"]
}
```

### 5.2 CLI

```bash
# ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰
code-graph index build --path ./my-project --languages typescript,python

# æ¤œç´¢
code-graph search "ãƒ¦ãƒ¼ã‚¶ãƒ¼èªè¨¼ã®å‡¦ç†" --top-k 3 --max-tokens 8000

# çµ±åˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç·¨é›†
code-graph edit "authenticateUser ã‚’ verifyUser ã«å¤‰æ›´" --preview
code-graph edit "authenticateUser ã‚’ verifyUser ã«å¤‰æ›´" --apply

# ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°
code-graph refactor "ã“ã®é–¢æ•°ã‚’3ã¤ã«åˆ†å‰²" --target src/auth.ts:45

# ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ã‚¿ãƒ«æ›´æ–°
code-graph index update --files src/auth.ts src/user.ts

# ã‚°ãƒ©ãƒ•å¯è¦–åŒ–
code-graph visualize --node func_123 --depth 2
```

## 6. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

### 6.1 ä¸¦åˆ—å‡¦ç†

```rust
// ãƒ•ã‚¡ã‚¤ãƒ«è§£æã®ä¸¦åˆ—åŒ–
fn parse_files_parallel(files: Vec<FilePath>) -> Vec<CodeNode> {
    files
        .par_iter()  // rayon ã«ã‚ˆã‚‹ä¸¦åˆ—ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚¿
        .flat_map(|file| {
            let ast = parse_file(file);
            extract_nodes(ast)
        })
        .collect()
}

// è¤‡æ•°èµ·ç‚¹ã®æ¢ç´¢ã‚’ä¸¦åˆ—åŒ–
fn explore_all_anchors_parallel(
    graph: &DependencyGraph,
    anchors: Vec<CodeNode>,
    config: SearchConfig,
) -> Vec<ContextGroup> {
    anchors
        .par_iter()
        .map(|anchor| {
            let nodes = explore_dependencies(graph, anchor, config);
            ContextGroup {
                anchor_node: anchor.clone(),
                related_nodes: nodes,
                relevance_score: anchor.relevance_score,
            }
        })
        .collect()
}
```

### 6.2 ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°

```rust
struct SearchCache {
    // ã‚¯ã‚¨ãƒª â†’ èµ·ç‚¹ãƒãƒ¼ãƒ‰ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥
    anchor_cache: LruCache<String, Vec<(CodeNode, f32)>>,
    
    // ãƒãƒ¼ãƒ‰ID â†’ æ¢ç´¢çµæœã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥
    exploration_cache: LruCache<String, Vec<CodeNode>>,
}

impl SearchCache {
    fn get_or_compute_anchors<F>(
        &mut self,
        query: &str,
        compute: F,
    ) -> Vec<(CodeNode, f32)>
    where
        F: FnOnce() -> Vec<(CodeNode, f32)>,
    {
        if let Some(cached) = self.anchor_cache.get(query) {
            return cached.clone();
        }
        
        let result = compute();
        self.anchor_cache.put(query.to_string(), result.clone());
        result
    }
}
```

### 6.3 ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æœ€é©åŒ–

```rust
// éš£æ¥ãƒªã‚¹ãƒˆã®äº‹å‰æ§‹ç¯‰
struct OptimizedGraph {
    nodes: HashMap<String, CodeNode>,
    
    // é«˜é€Ÿæ¢ç´¢ç”¨ã®éš£æ¥ãƒªã‚¹ãƒˆ
    callees: HashMap<String, Vec<String>>,      // å‘¼ã³å‡ºã—å…ˆ
    callers: HashMap<String, Vec<String>>,      // å‘¼ã³å‡ºã—å…ƒ
    type_refs: HashMap<String, Vec<String>>,    // å‹å‚ç…§
}

// RocksDB ã«ã‚ˆã‚‹æ°¸ç¶šåŒ–
fn save_graph_to_disk(graph: &DependencyGraph, path: &str) {
    let db = rocksdb::DB::open_default(path).unwrap();
    
    // ãƒãƒ¼ãƒ‰ã‚’ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºã—ã¦ä¿å­˜
    for (id, node) in &graph.nodes {
        let serialized = bincode::serialize(node).unwrap();
        db.put(format!("node:{}", id), serialized).unwrap();
    }
    
    // ã‚¨ãƒƒã‚¸ã‚‚åŒæ§˜ã«ä¿å­˜
    for edge in &graph.edges {
        let serialized = bincode::serialize(edge).unwrap();
        db.put(format!("edge:{}", edge.from_node), serialized).unwrap();
    }
}
```

## 7. ãƒ†ã‚¹ãƒˆæˆ¦ç•¥

### 7.1 å˜ä½“ãƒ†ã‚¹ãƒˆ

```rust
#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_bfs_forward() {
        let graph = create_test_graph();
        let mut visited = HashSet::new();
        
        let result = bfs_forward(&graph, "func_a", 2, &mut visited);
        
        assert_eq!(result.len(), 3);
        assert!(result.iter().any(|n| n.name == "func_b"));
    }
    
    #[test]
    fn test_priority_calculation() {
        let anchor = create_test_node("func_a", "file1.ts");
        let same_file = create_test_node("func_b", "file1.ts");
        let diff_file = create_test_node("func_c", "file2.ts");
        
        let score1 = calculate_priority(&same_file, &anchor);
        let score2 = calculate_priority(&diff_file, &anchor);
        
        assert!(score1 > score2);
    }
}
```

### 7.2 çµ±åˆãƒ†ã‚¹ãƒˆ

```rust
#[test]
fn test_end_to_end_search() {
    // 1. ãƒ†ã‚¹ãƒˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰
    let project_path = "tests/fixtures/sample_project";
    let graph = build_dependency_graph(project_path);
    
    // 2. æ¤œç´¢å®Ÿè¡Œ
    let request = SearchRequest {
        query: "user authentication".to_string(),
        top_k: 3,
        max_hops_forward: 2,
        max_hops_backward: 1,
        max_tokens: 8000,
    };
    
    let result = hybrid_search(&graph, request);
    
    // 3. æ¤œè¨¼
    assert!(!result.contexts.is_empty());
    assert!(result.total_tokens <= 8000);
    assert!(result.contexts[0].anchor_node.name.contains("auth"));
}
```

### 7.3 çµ±åˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç·¨é›†ã®ãƒ†ã‚¹ãƒˆ

```rust
#[test]
fn test_unified_context_edit() {
    // 1. ãƒ†ã‚¹ãƒˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®æº–å‚™
    let project = create_test_project();
    let graph = build_dependency_graph(&project);
    
    // 2. çµ±åˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
    let anchors = find_anchor_nodes("authenticateUser", 1);
    let context = create_unified_context(&graph, anchors);
    
    // 3. å¤‰æ›´è¨ˆç”»ç”Ÿæˆï¼ˆãƒ¢ãƒƒã‚¯ï¼‰
    let plan = ChangePlan {
        changes: vec![
            FileChange {
                file_path: "src/auth.ts".to_string(),
                edits: vec![
                    Edit {
                        start_line: 45,
                        end_line: 45,
                        old_content: "function authenticateUser()".to_string(),
                        new_content: "function verifyUser()".to_string(),
                        reason: "é–¢æ•°åå¤‰æ›´".to_string(),
                    }
                ],
            }
        ],
    };
    
    // 4. é©ç”¨
    apply_change_plan(plan).unwrap();
    
    // 5. æ¤œè¨¼
    let content = read_file("src/auth.ts");
    assert!(content.contains("function verifyUser()"));
    assert!(!content.contains("function authenticateUser()"));
}

#[test]
fn test_change_plan_rollback() {
    let project = create_test_project();
    
    // æ„å›³çš„ã«ã‚¨ãƒ©ãƒ¼ã‚’èµ·ã“ã™å¤‰æ›´è¨ˆç”»
    let plan = create_invalid_change_plan();
    
    let original_content = read_file("src/auth.ts");
    
    // é©ç”¨ã¯å¤±æ•—ã™ã‚‹ã¯ãš
    let result = apply_change_plan(plan);
    assert!(result.is_err());
    
    // ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
    let current_content = read_file("src/auth.ts");
    assert_eq!(original_content, current_content);
}
```

### 7.4 ç²¾åº¦è©•ä¾¡

```rust
// æ­£è§£ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨æ„
struct GroundTruth {
    query: String,
    expected_functions: Vec<String>, // æœŸå¾…ã•ã‚Œã‚‹é–¢æ•°å
}

fn evaluate_precision_recall(
    graph: &DependencyGraph,
    test_cases: Vec<GroundTruth>,
) -> (f32, f32) {
    let mut total_precision = 0.0;
    let mut total_recall = 0.0;
    
    for case in test_cases {
        let result = hybrid_search(graph, case.query);
        let retrieved: HashSet<_> = result.contexts
            .iter()
            .flat_map(|g| g.related_nodes.iter().map(|n| &n.name))
            .collect();
        
        let expected: HashSet<_> = case.expected_functions.iter().collect();
        
        let tp = retrieved.intersection(&expected).count() as f32;
        let precision = tp / retrieved.len() as f32;
        let recall = tp / expected.len() as f32;
        
        total_precision += precision;
        total_recall += recall;
    }
    
    let n = test_cases.len() as f32;
    (total_precision / n, total_recall / n)
}
```

## 8. ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ

### 8.1 æ§‹æˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CLI Tool  â”‚  (ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œ)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ã¾ãŸã¯

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  IDE Plugin â”‚ â”€â”€â”€> â”‚  API Server  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                     â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
                     â”‚             â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
              â”‚ Vector DB  â”‚ â”‚ Graph DB â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 8.2 è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«

```toml
# config.toml

[project]
path = "./my-project"
languages = ["typescript", "python", "rust"]

[indexing]
incremental = true
watch_mode = false
exclude_patterns = ["node_modules", "dist", "build"]

[search]
default_top_k = 3
max_hops_forward = 2
max_hops_backward = 1
max_tokens = 8000

[vector_db]
type = "qdrant"
host = "localhost"
port = 6333

[embedding]
model = "microsoft/graphcodebert-base"
device = "cpu"  # or "cuda"

[performance]
num_threads = 8
cache_size_mb = 512
```

## 9. ç›£è¦–ãƒ»ãƒ­ã‚°

```rust
// ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
struct Metrics {
    search_latency: Histogram,
    index_build_time: Histogram,
    cache_hit_rate: Counter,
    graph_size: Gauge,
}

// ãƒ­ã‚°å‡ºåŠ›
fn log_search(query: &str, result: &SearchResult, duration: Duration) {
    info!(
        query = query,
        num_contexts = result.contexts.len(),
        total_tokens = result.total_tokens,
        duration_ms = duration.as_millis(),
        "Search completed"
    );
}
```

## 10. Graph Keeper: ã‚³ãƒ¼ãƒ‰å¥å…¨æ€§ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 

### 10.1 ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      å¤§å‹ LLM (GPT-4 ãªã©)          â”‚
â”‚   (ã‚³ãƒ¼ãƒ‰ç”Ÿæˆãƒ»ç·¨é›†)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â”‚ ç›¸è«‡ãƒ»æ¤œè¨¼
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Graph Keeper (å°å‹ç‰¹åŒ–å‹ LLM)      â”‚
â”‚   - æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯                   â”‚
â”‚   - ãƒ‡ãƒƒãƒ‰ã‚³ãƒ¼ãƒ‰æ¤œå‡º                 â”‚
â”‚   - æœ€é©åŒ–ææ¡ˆ                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â”‚ ç›£è¦–ãƒ»æ›´æ–°
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        ä¾å­˜ã‚°ãƒ©ãƒ• DB                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 10.2 ãƒ‡ãƒƒãƒ‰ã‚³ãƒ¼ãƒ‰æ¤œå‡º

```rust
// ãƒ‡ãƒƒãƒ‰ã‚³ãƒ¼ãƒ‰æ¤œå‡ºã®ç¨®é¡
enum DeadCodeType {
    Orphaned,       // å®Œå…¨ã«ä½¿ã‚ã‚Œã¦ã„ãªã„
    Zombie,         // ä½•ã‚‚ã—ã¦ã„ãªã„
    UnusedImport,   // æœªä½¿ç”¨ã® import
    Unreachable,    // åˆ°é”ä¸å¯èƒ½
    Deprecated,     // å¤ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³
    Untested,       // ãƒ†ã‚¹ãƒˆãŒãªã„
}

struct CodeHealthReport {
    dead_code: Vec<DeadCodeItem>,
    total_waste_lines: usize,
    cleanup_tasks: Vec<CleanupTask>,
    technical_debt_score: f32,
}

struct DeadCodeItem {
    node: CodeNode,
    dead_type: DeadCodeType,
    reason: String,
    last_modified: DateTime,
}

struct CleanupTask {
    item: DeadCodeItem,
    priority: Priority,      // High, Medium, Low
    risk: Risk,              // None, Low, Medium, High
    estimated_impact: String,
}
```

### 10.3 æ¤œå‡ºã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 

```rust
impl GraphKeeper {
    // å­¤ç«‹ãƒãƒ¼ãƒ‰ï¼ˆãƒ‡ãƒƒãƒ‰ã‚³ãƒ¼ãƒ‰ï¼‰ã®æ¤œå‡º
    fn find_orphaned_nodes(&self, graph: &DependencyGraph) -> Vec<CodeNode> {
        graph.nodes
            .values()
            .filter(|node| {
                // å‘¼ã³å‡ºã—å…ƒãŒ0å€‹ = èª°ã‚‚ä½¿ã£ã¦ã„ãªã„
                graph.get_callers(&node.id).is_empty() &&
                // ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆã§ã‚‚ãªã„
                !self.is_entry_point(node) &&
                // ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„
                !self.is_exported(node)
            })
            .cloned()
            .collect()
    }
    
    // ã‚¾ãƒ³ãƒ“ã‚³ãƒ¼ãƒ‰ï¼ˆä½•ã‚‚ã—ã¦ã„ãªã„ï¼‰ã®æ¤œå‡º
    fn find_zombie_code(&self, graph: &DependencyGraph) -> Vec<CodeNode> {
        graph.nodes
            .values()
            .filter(|node| {
                // å‘¼ã³å‡ºã—å…ˆãŒ0å€‹ï¼ˆä½•ã‚‚ã—ã¦ã„ãªã„ï¼‰
                let callees = graph.get_callees(&node.id);
                callees.is_empty() ||
                // ã¾ãŸã¯å˜ç´”ãªãƒ©ãƒƒãƒ‘ãƒ¼
                (callees.len() == 1 && self.is_simple_wrapper(node))
            })
            .cloned()
            .collect()
    }
    
    // æœªä½¿ç”¨ import ã®æ¤œå‡º
    fn find_unused_imports(&self, graph: &DependencyGraph) -> Vec<String> {
        let mut unused = Vec::new();
        
        for file in graph.get_all_files() {
            let imports = graph.get_imports(&file);
            let used_symbols = graph.get_used_symbols(&file);
            
            for import in imports {
                if !used_symbols.contains(&import) {
                    unused.push(format!("{}:{}", file, import));
                }
            }
        }
        
        unused
    }
    
    // å¤ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®æ®‹éª¸æ¤œå‡º
    fn find_deprecated_code(&self, graph: &DependencyGraph) -> Vec<CodeNode> {
        let mut deprecated = Vec::new();
        
        // åå‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã§æ¤œå‡ºï¼ˆv1, v2, old, legacy ãªã©ï¼‰
        for node in graph.nodes.values() {
            if self.has_version_suffix(&node.name) ||
               self.has_deprecated_prefix(&node.name) {
                // æ–°ã—ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
                if self.has_newer_version(graph, node) {
                    deprecated.push(node.clone());
                }
            }
        }
        
        deprecated
    }
    
    // ãƒ†ã‚¹ãƒˆã•ã‚Œã¦ã„ãªã„ã‚³ãƒ¼ãƒ‰æ¤œå‡º
    fn find_untested_code(&self, graph: &DependencyGraph) -> Vec<CodeNode> {
        let test_files = graph.get_test_files();
        let production_code = graph.get_production_code();
        
        production_code
            .into_iter()
            .filter(|node| {
                // ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å‘¼ã°ã‚Œã¦ã„ãªã„
                !self.has_test_coverage(graph, node, &test_files)
            })
            .collect()
    }
    
    // å¥å…¨æ€§ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    fn generate_health_report(&self, graph: &DependencyGraph) -> CodeHealthReport {
        let orphaned = self.find_orphaned_nodes(graph);
        let zombie = self.find_zombie_code(graph);
        let unused_imports = self.find_unused_imports(graph);
        let deprecated = self.find_deprecated_code(graph);
        let untested = self.find_untested_code(graph);
        
        let mut dead_code = Vec::new();
        
        // å„ç¨®ãƒ‡ãƒƒãƒ‰ã‚³ãƒ¼ãƒ‰ã‚’çµ±åˆ
        for node in orphaned {
            dead_code.push(DeadCodeItem {
                node,
                dead_type: DeadCodeType::Orphaned,
                reason: "ã©ã“ã‹ã‚‰ã‚‚å‘¼ã°ã‚Œã¦ã„ã¾ã›ã‚“".to_string(),
                last_modified: self.get_last_modified(&node),
            });
        }
        
        for node in zombie {
            dead_code.push(DeadCodeItem {
                node,
                dead_type: DeadCodeType::Zombie,
                reason: "ä½•ã‚‚ã—ã¦ã„ãªã„é–¢æ•°ã§ã™".to_string(),
                last_modified: self.get_last_modified(&node),
            });
        }
        
        // ç·è¡Œæ•°è¨ˆç®—
        let total_waste_lines = dead_code.iter()
            .map(|item| item.node.end_line - item.node.start_line)
            .sum();
        
        // ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¿ã‚¹ã‚¯ç”Ÿæˆ
        let cleanup_tasks = self.prioritize_cleanup(&dead_code);
        
        // æŠ€è¡“çš„è² å‚µã‚¹ã‚³ã‚¢è¨ˆç®—
        let technical_debt_score = self.calculate_debt_score(
            &dead_code,
            graph.total_lines(),
        );
        
        CodeHealthReport {
            dead_code,
            total_waste_lines,
            cleanup_tasks,
            technical_debt_score,
        }
    }
    
    // ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã®å„ªå…ˆåº¦ä»˜ã‘
    fn prioritize_cleanup(&self, dead_code: &[DeadCodeItem]) -> Vec<CleanupTask> {
        let mut tasks = Vec::new();
        
        for item in dead_code {
            let (priority, risk) = match item.dead_type {
                DeadCodeType::Orphaned => (Priority::High, Risk::None),
                DeadCodeType::UnusedImport => (Priority::High, Risk::None),
                DeadCodeType::Zombie => (Priority::Medium, Risk::Low),
                DeadCodeType::Deprecated => (Priority::Medium, Risk::Low),
                DeadCodeType::Unreachable => (Priority::Low, Risk::None),
                DeadCodeType::Untested => (Priority::Low, Risk::Medium),
            };
            
            tasks.push(CleanupTask {
                item: item.clone(),
                priority,
                risk,
                estimated_impact: self.estimate_impact(item),
            });
        }
        
        // å„ªå…ˆåº¦é †ã«ã‚½ãƒ¼ãƒˆ
        tasks.sort_by_key(|t| (t.priority, t.risk));
        tasks
    }
}
```

### 10.4 è‡ªå‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—

```rust
fn auto_cleanup(
    graph: &mut DependencyGraph,
    report: &CodeHealthReport,
    dry_run: bool,
) -> CleanupResult {
    let mut removed_lines = 0;
    let mut removed_files = 0;
    let mut actions = Vec::new();
    
    for task in &report.cleanup_tasks {
        // ãƒªã‚¹ã‚¯ãŒé«˜ã„ã‚‚ã®ã¯ã‚¹ã‚­ãƒƒãƒ—
        if task.risk == Risk::High {
            continue;
        }
        
        // ãƒ¦ãƒ¼ã‚¶ãƒ¼ç¢ºèªãŒå¿…è¦ãªã‚‚ã®ã¯ã‚¹ã‚­ãƒƒãƒ—
        if task.risk == Risk::Medium && !dry_run {
            println!("âš ï¸  è¦ç¢ºèª: {} - {}", task.item.node.name, task.item.reason);
            continue;
        }
        
        match task.item.dead_type {
            DeadCodeType::UnusedImport => {
                if !dry_run {
                    remove_import(&task.item.node);
                }
                actions.push(format!("âœ“ import å‰Šé™¤: {}", task.item.node.name));
            }
            DeadCodeType::Orphaned => {
                let lines = task.item.node.end_line - task.item.node.start_line;
                if !dry_run {
                    remove_code(&task.item.node);
                }
                removed_lines += lines;
                actions.push(format!("âœ“ é–¢æ•°å‰Šé™¤: {} ({}è¡Œ)", task.item.node.name, lines));
            }
            _ => {}
        }
    }
    
    CleanupResult {
        removed_lines,
        removed_files,
        actions,
    }
}
```

### 10.5 CLI ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹

```bash
# ã‚³ãƒ¼ãƒ‰å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯
$ code-graph health-check

ğŸ“Š ã‚³ãƒ¼ãƒ‰å¥å…¨æ€§ãƒ¬ãƒãƒ¼ãƒˆ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ—‘ï¸  ãƒ‡ãƒƒãƒ‰ã‚³ãƒ¼ãƒ‰: 23å€‹ (456è¡Œ)
â”œâ”€ src/old-auth.ts:45-78 (oldAuthMethod)
â”‚  ç†ç”±: ã©ã“ã‹ã‚‰ã‚‚å‘¼ã°ã‚Œã¦ã„ã¾ã›ã‚“
â”‚  æœ€çµ‚æ›´æ–°: 2023-03-15
â”œâ”€ src/utils.ts:123-145 (deprecatedHelper)
â”‚  ç†ç”±: æ–°ã—ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒå­˜åœ¨ã—ã¾ã™
â”‚  æœ€çµ‚æ›´æ–°: 2023-01-20
â””â”€ src/legacy.ts:1-234 (ãƒ•ã‚¡ã‚¤ãƒ«å…¨ä½“)
   ç†ç”±: å®Œå…¨ã«æœªä½¿ç”¨
   æœ€çµ‚æ›´æ–°: 2022-11-10

ğŸ§Ÿ ã‚¾ãƒ³ãƒ“ã‚³ãƒ¼ãƒ‰: 8å€‹ (92è¡Œ)
â”œâ”€ src/logger.ts:34-38 (emptyLogger)
â”‚  ç†ç”±: ä½•ã‚‚ã—ã¦ã„ãªã„é–¢æ•°
â””â”€ src/wrapper.ts:12-15 (simpleWrapper)
   ç†ç”±: å˜ç´”ãªãƒ©ãƒƒãƒ‘ãƒ¼é–¢æ•°

ğŸ“¦ æœªä½¿ç”¨ import: 15å€‹
â”œâ”€ src/main.ts: oldFunction, deprecatedUtil
â””â”€ src/app.ts: unusedHelper

âš ï¸  ãƒ†ã‚¹ãƒˆãªã—: 34å€‹ã®é–¢æ•°

ğŸ’¾ å‰Šæ¸›å¯èƒ½ãªè¡Œæ•°: 548è¡Œ (å…¨ä½“ã® 12%)
ğŸ“‰ æŠ€è¡“çš„è² å‚µã‚¹ã‚³ã‚¢: 7.2/10 (è¦æ”¹å–„)

ğŸ¯ æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:
1. [å®‰å…¨] src/legacy.ts ã‚’å‰Šé™¤ (234è¡Œå‰Šæ¸›)
2. [å®‰å…¨] æœªä½¿ç”¨ import ã‚’å‰Šé™¤ (15ç®‡æ‰€)
3. [è¦ç¢ºèª] ã‚¾ãƒ³ãƒ“ã‚³ãƒ¼ãƒ‰ã‚’ç¢ºèª (8ç®‡æ‰€)

è‡ªå‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’å®Ÿè¡Œã—ã¾ã™ã‹? (y/n)

# ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ï¼ˆå®Ÿéš›ã«ã¯å‰Šé™¤ã—ãªã„ï¼‰
$ code-graph cleanup --dry-run

# è‡ªå‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Ÿè¡Œ
$ code-graph cleanup --auto

ğŸ§¹ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Ÿè¡Œä¸­...

âœ“ import å‰Šé™¤: oldFunction (src/main.ts)
âœ“ import å‰Šé™¤: deprecatedUtil (src/main.ts)
âœ“ é–¢æ•°å‰Šé™¤: oldAuthMethod (45è¡Œ)
âœ“ ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤: src/legacy.ts (234è¡Œ)

ğŸ“Š ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†
å‰Šæ¸›ã—ãŸè¡Œæ•°: 548è¡Œ
å‰Šæ¸›ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«: 3å€‹
æŠ€è¡“çš„è² å‚µæ”¹å–„: 7.2 â†’ 5.1 (-29%)
```

### 10.6 IDE çµ±åˆ

```typescript
// VSCode æ‹¡å¼µã§ã®è¡¨ç¤ºä¾‹
function oldAuthMethod() {  // âš ï¸ ãƒ‡ãƒƒãƒ‰ã‚³ãƒ¼ãƒ‰: ã©ã“ã‹ã‚‰ã‚‚å‘¼ã°ã‚Œã¦ã„ã¾ã›ã‚“
    // ...                  // ğŸ’¡ ã‚¯ãƒªãƒƒã‚¯ã—ã¦å‰Šé™¤
}

import { oldFunction } from './utils';  // âš ï¸ æœªä½¿ç”¨ã® import
                                        // ğŸ’¡ ã‚¯ãƒªãƒƒã‚¯ã—ã¦å‰Šé™¤

function emptyLogger() {  // ğŸ’€ ã‚¾ãƒ³ãƒ“ã‚³ãƒ¼ãƒ‰: ä½•ã‚‚ã—ã¦ã„ã¾ã›ã‚“
    return;               // ğŸ’¡ ã‚¯ãƒªãƒƒã‚¯ã—ã¦å‰Šé™¤
}
```

## 11. ã¾ã¨ã‚

æœ¬è¨­è¨ˆæ›¸ã§ã¯ã€ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã¨ã‚°ãƒ©ãƒ•æ¢ç´¢ã‚’çµ„ã¿åˆã‚ã›ãŸãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã€çµ±åˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«ã‚ˆã‚‹ä¸€æ‹¬ç·¨é›†æ©Ÿèƒ½ã€ãŠã‚ˆã³ Graph Keeper ã«ã‚ˆã‚‹ã‚³ãƒ¼ãƒ‰å¥å…¨æ€§ç®¡ç†ã®è©³ç´°ã‚’å®šç¾©ã—ãŸã€‚

**ä¸»è¦ãªè¨­è¨ˆåˆ¤æ–­**:
- Rust ã«ã‚ˆã‚‹é«˜æ€§èƒ½å®Ÿè£…
- tree-sitter ã«ã‚ˆã‚‹å¤šè¨€èªå¯¾å¿œ
- ãƒˆãƒƒãƒ—kèµ·ç‚¹ + BFSæ¢ç´¢ã®çµ„ã¿åˆã‚ã›
- å„ªå…ˆåº¦ãƒ™ãƒ¼ã‚¹ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
- çµ±åˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«ã‚ˆã‚‹æ•´åˆæ€§ã®é«˜ã„ä¸€æ‹¬ç·¨é›†
- Graph Keeper ã«ã‚ˆã‚‹ç¶™ç¶šçš„ãªã‚³ãƒ¼ãƒ‰å“è³ªç¶­æŒ
- ãƒ‡ãƒƒãƒ‰ã‚³ãƒ¼ãƒ‰è‡ªå‹•æ¤œå‡ºã¨ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
- ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³çš„ãªå¤‰æ›´é©ç”¨ã¨ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿæ§‹
- ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ã‚¿ãƒ«æ›´æ–°ã«ã‚ˆã‚‹é«˜é€ŸåŒ–

**çµ±åˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç·¨é›†ã®åˆ©ç‚¹**:
- è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¾ãŸãŒã‚‹å¤‰æ›´ã‚’ä¸€åº¦ã«å‡¦ç†
- LLM ãŒå…¨ä½“ã‚’è¦‹ã‚‹ãŸã‚æ•´åˆæ€§ãŒä¿ãŸã‚Œã‚‹
- å¤‰æ›´æ¼ã‚Œã®ãƒªã‚¹ã‚¯ã‚’å¤§å¹…ã«å‰Šæ¸›
- ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼æ©Ÿèƒ½ã«ã‚ˆã‚‹å®‰å…¨ãªé©ç”¨

**Graph Keeper ã®åˆ©ç‚¹**:
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ã‚³ãƒ¼ãƒ‰ã®å¥å…¨æ€§ã‚’ç›£è¦–
- ãƒ‡ãƒƒãƒ‰ã‚³ãƒ¼ãƒ‰ã€ã‚¾ãƒ³ãƒ“ã‚³ãƒ¼ãƒ‰ã€æœªä½¿ç”¨ import ã‚’è‡ªå‹•æ¤œå‡º
- æŠ€è¡“çš„è² å‚µã®å®šé‡è©•ä¾¡ã¨å¯è¦–åŒ–
- å®‰å…¨æ€§ã‚’è€ƒæ…®ã—ãŸå„ªå…ˆåº¦ä»˜ãã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
- ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®è‚¥å¤§åŒ–ã‚’é˜²æ­¢

**æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—**:
1. MVP å®Ÿè£…ï¼ˆå˜ä¸€è¨€èªã€åŸºæœ¬æ©Ÿèƒ½ã®ã¿ï¼‰
2. ãƒ‡ãƒƒãƒ‰ã‚³ãƒ¼ãƒ‰æ¤œå‡ºã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®å®Ÿè£…ã¨æ¤œè¨¼
3. å°è¦æ¨¡ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã®ç²¾åº¦æ¤œè¨¼
4. çµ±åˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç·¨é›†ã®å®Ÿç”¨æ€§æ¤œè¨¼
5. Graph Keeper ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã¨è¨“ç·´
6. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
7. æ®µéšçš„ãªæ©Ÿèƒ½æ‹¡å¼µ
